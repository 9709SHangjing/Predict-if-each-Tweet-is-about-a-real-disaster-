{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "<h1 align=\"center\"> <font size=\"30\"> CS5785 HW 2 -- Applied Machine Learning </font>  </h1>  \n",
    "\n",
    "-------\n",
    "\n",
    "<h1 align=\"center\"> <font size=\"5\"> Student: Shangjing Tang(st787)， Katherine Wu(Kw634) </font> </h1>  \n",
    "&nbsp;\n",
    "&NewLine;\n",
    "&NewLine;\n",
    "\n",
    "<h1 align=\"center\"> <font size=\"5\"> Due Date: September 29th </font> </h1> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always; break-after: page;\"></div>\n",
    "<h1 align=\"center\"> <font size=\"5\"> PROGRAMMING EXERCISES </font> </h1>\n",
    "\n",
    "#### Part I.  Binary Classification on Text Data\n",
    "In this problem,you will implement several machine learning techniques from the class to perform classification on text data. Throughout the problem, we will be working on the NLP with Disaster Tweets Kaggle competition, where the task is to predict whether or not a tweet is about a real disaster.\n",
    "\n",
    "* Download the training and test data from Kaggle,and answer the follow-ing questions: (1) how many training and test data points are there? and (2) what percentage of the training tweets are of real disasters, and what percentage is not? Note that the meaning of each column is explained in the data description on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data points are: 7613\n",
      "The number of testing data points are: 3263\n",
      "The percentage of real disaster in trainning data is 42.97%\n",
      "The percentage of fake disaster in trainning data is 57.03%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import string\n",
    "from scipy.stats import skew\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "workingDirectory = os.getcwd()\n",
    "trainData = pd.read_csv(workingDirectory+\"/train.csv\")\n",
    "testData = pd.read_csv(workingDirectory+ \"/test.csv\")\n",
    "all_data = pd.concat([trainData, testData], axis=0) #merge both trainig\n",
    "\n",
    "train_target = pd.DataFrame(trainData['target'].value_counts()) \n",
    "\n",
    "print(\"The number of training data points are:\", len(trainData.index))\n",
    "print(\"The number of testing data points are:\", len(testData.index))\n",
    "print(\"The percentage of real disaster in trainning data is %.2f%%\" %(train_target.loc[1]/len(trainData.index) *100)  )\n",
    "print(\"The percentage of fake disaster in trainning data is %.2f%%\" % (train_target.loc[0]/len(trainData.index)*100))\n",
    "\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "# plt.hist(con_feat1, bins=30,facecolor = '#2ab0ff', edgecolor='#169acf', linewidth=0.5)  # density=False would make counts\n",
    "# plt.ylabel('distribution')\n",
    "# plt.xlabel('Sale price')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "# plt.hist(cat_feat4, bins=30,facecolor = '#2ab0ff', edgecolor='#169acf', linewidth=0.5)  # density=False would make counts\n",
    "# plt.ylabel('distribution')\n",
    "# plt.xlabel('sale condition')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10876"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since the data consists of tweets,they may contain significant amounts of noise and unprocessed content. You may or may not want to do one or all of the following. Explain the reasons for each of your decision (why or why not).\n",
    "    - Convert all the words to lower case.\n",
    "    - Lemmatize all the words (i.e.,convert every word to its root so that all of “running,”“run,” and “runs” are converted to “run” and and all of “good,” “well,” “better,” and “best” are converted to “good”; this is easily done using nltk.stem).\n",
    "    - Strip punctuation.\n",
    "    - Strip the stop words,e.g.,“the”,“and”,“or”.\n",
    "    - Strip @ and urls.(It’sTwitter.)\n",
    "    - Something else? Tell us about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prettygirl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/prettygirl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/prettygirl/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/prettygirl/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing -- Lowercase----------------------------------------------------------------------------------------------------------\n",
    "trainData['text'] = trainData['text'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "## strip urls-------------------------------------------------------------------------------------------------------------------\n",
    "for l in range(0,len(trainData['text'])): \n",
    "    trainData['text'][l] = re.sub(r'http\\S+', '', trainData['text'][l])\n",
    "    trainData['text'][l] = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', trainData['text'][l])\n",
    "\n",
    "    \n",
    "## get ride of punctuation----------------------------------------------------------------------------------------------------------\n",
    "trainData['text'] = trainData['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "\n",
    "## strip stop words ----------------------------------------------------------------------------------------------------------\n",
    "text_token = []\n",
    "temp = trainData['text']\n",
    "for i in range(0,len(trainData['text'])): \n",
    "   text_token.append(word_tokenize(temp[i]))\n",
    "for row in range(0,len(text_token)):\n",
    "    for word in text_token[row]:\n",
    "        if word in stopwords.words('english'):\n",
    "            text_token[row].remove(word)\n",
    "        \n",
    "            \n",
    "    text_token[row] =  (\" \").join(text_token[row])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Lamatize ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "clean_token = []\n",
    "lemmatized_sentence = []\n",
    "\n",
    "for l in range(0,len(text_token)):\n",
    "    text_token[l] = nlp(text_token[l])\n",
    "    for tokes in text_token[l]:\n",
    "        clean_token.append(tokes)\n",
    "        \n",
    "    lemmatized_sentence.append(\" \".join([tokes.lemma_ for tokes in text_token[l]]))  \n",
    "    \n",
    "\n",
    "clean_sentence = pd.DataFrame({'clean_Text':lemmatized_sentence})\n",
    "new_trainData = pd.concat([trainData, clean_sentence],join = 'outer', axis = 1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed the reason this earthquake may allah forg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place be notify officer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant crane hold bridge collapse nearby home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ariaahrary thetawniest the out of control wild...</td>\n",
       "      <td>1</td>\n",
       "      <td>ariaahrary thetawni out control wild fire cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m194 0104 utc5km s of volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "      <td>m194 0104 utc5 km of volcano hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigate an ebike collide a car litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "      <td>1</td>\n",
       "      <td>late home raze northern california wildfire ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     our deeds are the reason of this earthquake ma...       1   \n",
       "1                 forest fire near la ronge sask canada       1   \n",
       "2     all residents asked to shelter in place are be...       1   \n",
       "3     13000 people receive wildfires evacuation orde...       1   \n",
       "4     just got sent this photo from ruby alaska as s...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  two giant cranes holding a bridge collapse int...       1   \n",
       "7609  ariaahrary thetawniest the out of control wild...       1   \n",
       "7610              m194 0104 utc5km s of volcano hawaii        1   \n",
       "7611  police investigating after an ebike collided w...       1   \n",
       "7612  the latest more homes razed by northern califo...       1   \n",
       "\n",
       "                                             clean_Text  \n",
       "0     deed the reason this earthquake may allah forg...  \n",
       "1                 forest fire near la ronge sask canada  \n",
       "2     resident ask shelter place be notify officer o...  \n",
       "3     13000 people receive wildfire evacuation order...  \n",
       "4     got send photo ruby alaska smoke wildfire pour...  \n",
       "...                                                 ...  \n",
       "7608   two giant crane hold bridge collapse nearby home  \n",
       "7609  ariaahrary thetawni out control wild fire cali...  \n",
       "7610                m194 0104 utc5 km of volcano hawaii  \n",
       "7611  police investigate an ebike collide a car litt...  \n",
       "7612  late home raze northern california wildfire ab...  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sanity check\n",
    "new_trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> \n",
    "    During the preprocessing step, we decided to first convert all letters into lowercase, becasue we don't want the model to treat same contents differently based on their cases. We then stripped all the urls from the text by using re.sub becasue urls are not helpful information in our cases. After this we strip other useless information such as punctuations and stopwords. Finally, we perform lamatization to each word token to rind their wording root. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the training data. Since we do not know the correct values of labels in the test data, we will split the training data from Kaggle into a training set and a development set (a de- velopment set is a held out subset of the labeled data that we set aside in order to fine-tune models, before evaluating the best model(s) on the test data). Randomly choose 70% of the data points in the training data as the training set, and the remaining 30% of the data as the development set. Throughout the rest of this problem we will keep these two sets fixed. The idea is that we will train different models on the training set, and compare their performance on the development set, in order to decide what to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = pd.concat([trainData['target'], clean_sentence],join = 'outer', axis = 1)\n",
    "y = newData['target']\n",
    "indep = newData['clean_Text']\n",
    "x_train, x_valid,y_train,y_valid = train_test_split(indep, y, test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476     blazerfan everyone see ignoranceshe latinoand ...\n",
       "4854    white people know worry tirelessly black black...\n",
       "4270                  chilli heat wave doritos never fail\n",
       "992     broseidonrex dapurplesharpie skim twitter miss...\n",
       "4475    hot c130 specially modify land a stadium rescu...\n",
       "Name: clean_Text, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sanity check\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311     0\n",
       "4970    0\n",
       "527     0\n",
       "6362    0\n",
       "800     0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sanity check\n",
    "y_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> We split the data and randomly choose 70% of data as training data. Please see the sanity check above. .</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bag of words model.The next task is to extract features in order to represent each tweet using the binary “bag of words” model, as discussed in lectures. The idea is to build a vocabulary of the words appearing in the dataset, and then to represent each tweet by a feature vector x whose length is the same as the size of the vocabulary, where xi = 1 if the i ’th vocabulary word appears in that tweet, and xi = 0 otherwise. In order to build the vocabulary, you should choose some threshold M, and only include words that appear in at least k different tweets; this is important both to avoid run-time and memory issues, and to avoid noisy/unreliable features that can hurt learning. Decide on an appropriate threshold M , and discuss how you made this decision. Then, build the bag of words feature vectors for both the training and development sets, and report the total number of features in these vectors. \n",
    "    \n",
    "    In order to construct these features, we suggest using the CountVectorizer class in sklearn. A couple of notes on using this function: (1) you should set the option “binary=True” in order to ensure that the feature vectors are binary; and (2) you can use the option “min_df=M” in or- der to only include in the vocabulary words that appear in at least M different tweets. Finally, make sure you fit CountVectorizer only once on your training set and use the same instance to process both your training and development sets (don’t refit it on your development set a second time).\n",
    "\n",
    "    Important: at this point you should only be constructing feature vectors for each data point using the text in the “text” column. You should ignore the “keyword” and “location” columns for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With M = 1, F1 score = 0.7475\n",
      "With M = 2, F1 score = 0.7508\n",
      "With M = 3, F1 score = 0.7425\n",
      "With M = 4, F1 score = 0.7403\n",
      "With M = 5, F1 score = 0.7392\n",
      "With M = 6, F1 score = 0.7348\n",
      "With M = 7, F1 score = 0.7324\n",
      "With M = 8, F1 score = 0.7303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "for i in range(1,9):\n",
    "    CountVec = CountVectorizer(binary = True, min_df = i)\n",
    "    #transform\n",
    "    CountVec_train = CountVec.fit_transform(x_train).toarray()\n",
    "    CountVec_valid = CountVec.transform(x_valid).toarray()\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(CountVec_train,y_train)\n",
    "    predict_y = logreg.predict(CountVec_valid)\n",
    "    print('With M = %s, F1 score = %.4f' % (i, f1_score(y_valid, predict_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001116', '0104', '010401', '02', '0306', '05', '06', '070', '0700', '075', '0800', '09', '0day', '10', '100', '1000', '100000', '101', '1030', '1030pm', '10401', '1061thetwister', '109', '10th', '11', '1100', '118', '11yearold', '12', '1200', '12000', '125', '13', '13000', '133', '14', '15', '150', '150401', '150foot', '15th', '16', '161116', '1620', '166', '16yr', '17', '1716', '18', '180', '1800', '18w', '18wheeler', '19', '1916', '1943', '1965', '1976', '1979', '1980', '1998', '1st', '20', '2005', '2008', '2010', '2011', '2013', '2014', '2015', '20150805', '201516', '2030', '2082676773', '21', '21a', '22', '23', '233liveonline', '235409', '24', '25', '26', '27', '29', '29072015', '2nd', '2pcs', '2us', '30', '300', '300000', '300w', '31', '32', '320', '33', '34', '35', '36', '360', '360wisenews', '361', '370', '3942', '3d', '3rd', '40', '400', '4000', '45', '48', '4playthursdays', '4th', '4wd', '4x4', '50', '500', '5000', '53', '530', '53inch', '55', '56', '582', '5c', '5s', '5sos', '5th', '60', '600', '64', '66', '69', '6th', '70', '70th', '72w', '731', '78', '80', '800', '83', '84', '852015', '86', '8615', '87', '8pin', '8th', '90', '90blksamp8whts', '911', '928', '95', '96', '97georgia', 'a1', 'aa', 'aba', 'abandon', 'abbswinston', 'abc', 'abcnew', 'abe', 'abia', 'ability', 'ablaze', 'able', 'abomination', 'abortion', 'about', 'above', 'absolute', 'absolutely', 'abstorm', 'abuse', 'abuseddesolateamplost', 'ac', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accionempresa', 'accord', 'account', 'accuse', 'acdelco', 'achimota', 'acquire', 'acre', 'across', 'act', 'action', 'activate', 'active', 'activity', 'actress', 'actual', 'actually', 'acute', 'ad', 'adam', 'add', 'addict', 'addition', 'address', 'administration', 'admit', 'adult', 'advance', 'advanced', 'adventure', 'advisory', 'af', 'afc', 'affect', 'affected', 'afghan', 'afghanistan', 'afp', 'afraid', 'africa', 'africans', 'after', 'afterlife', 'afternoon', 'aftershock', 'aftershockdelo', 'ag', 'again', 'against', 'age', 'agency', 'agent', 'ago', 'agree', 'ah', 'ahead', 'ahh', 'aid', 'aim', 'air', 'aircraft', 'airline', 'airplane', 'airport', 'ak', 'aka', 'al', 'alabama', 'alarm', 'alaska', 'albany', 'alberta', 'album', 'alcohol', 'alert', 'alex', 'alexbelloli', 'alien', 'alive', 'all', 'allah', 'allege', 'allegiance', 'allow', 'alloy', 'ally', 'almost', 'alois', 'alone', 'along', 'alp', 'already', 'alright', 'also', 'alternative', 'always', 'am', 'amageddon', 'amazing', 'amazon', 'ambulance', 'america', 'american', 'americans', 'americas', 'amid', 'amirite', 'among', 'amongst', 'amp', 'amsterdam', 'an', 'analysis', 'anchorage', 'ancient', 'and', 'andor', 'andy', 'angel', 'angeles', 'anger', 'angry', 'animal', 'animalrescue', 'ankle', 'annihilate', 'annihilation', 'anniversary', 'announce', 'announcement', 'annual', 'another', 'answer', 'ant', 'anthrax', 'anti', 'antioch', 'antonio', 'anxiety', 'anxious', 'any', 'any1', 'anybody', 'anymore', 'anyone', 'anything', 'anyway', 'anyways', 'anza', 'aoms', 'ap', 'apartment', 'apc', 'apch', 'apocalypse', 'apocalyptic', 'apollo', 'apollobrown', 'apologize', 'app', 'apparent', 'apparently', 'appear', 'apple', 'application', 'apply', 'appreciate', 'approach', 'approval', 'approve', 'april', 'apt', 'aquarium', 'ar', 'arabia', 'arabian', 'architect', 'architecture', 'area', 'argument', 'arianagrande', 'arizona', 'arm', 'armageddon', 'armory', 'army', 'arnhem', 'around', 'arrest', 'arrive', 'ars', 'arsenal', 'arson', 'arsonist', 'art', 'article', 'artificial', 'artist', 'as', 'asap', 'ash', 'ashe', 'ashley', 'asia', 'asian', 'ask', 'askcharley', 'asleep', 'ass', 'asshole', 'assist', 'assistance', 'assistant', 'associate', 'association', 'asylum', 'at', 'atlanta', 'atlantic', 'atmosphere', 'atomic', 'attack', 'attempt', 'attend', 'attention', 'attitude', 'attractive', 'auction', 'audience', 'audio', 'aug', 'august', 'aussie', 'australia', 'australian', 'australias', 'auth', 'author', 'authority', 'autoinsurance', 'automatic', 'av', 'available', 'avalanche', 'ave', 'avenger', 'avenue', 'average', 'avert', 'avoid', 'aw', 'await', 'aware', 'awareness', 'away', 'awesome', 'awful', 'b4', 'babe', 'baby', 'back', 'background', 'backup', 'backyard', 'bad', 'badge', 'bag', 'bail', 'bake', 'bakeofffriend', 'bal', 'ball', 'baltimore', 'ban', 'band', 'banerjee', 'bang', 'bangin', 'bangladesh', 'bank', 'banquet', 'bar', 'barackobama', 'bare', 'barely', 'bargain', 'bark', 'barry', 'baruch', 'base', 'baseball', 'basement', 'bash', 'bass', 'bat', 'batfanuk', 'bath', 'bathroom', 'batter', 'battery', 'battle', 'battlefield', 'battleship', 'bay', 'bayelsa', 'bb17', 'bb4sp', 'bbc', 'bc', 'be', 'beach', 'beam', 'bean', 'bear', 'beard', 'beat', 'beautiful', 'beauty', 'because', 'beclearoncancer', 'become', 'bed', 'bedroom', 'bee', 'been', 'beer', 'before', 'beforeitsnew', 'begin', 'beginner', 'beginning', 'behalf', 'behavior', 'behind', 'belief', 'believe', 'bell', 'belong', 'belt', 'ben', 'bend', 'benefit', 'bengal', 'besides', 'bestnaijamade', 'bestseller', 'bet', 'bethlehem', 'betray', 'between', 'beyhive', 'beyonce', 'beyond', 'bff', 'bicep', 'bicycle', 'bicyclist', 'bid', 'bieber', 'big', 'bill', 'billboard', 'billing', 'billneelynbc', 'bin', 'bind', 'bio', 'biolab', 'biological', 'bioterror', 'bioterrorism', 'bird', 'birth', 'birthday', 'bit', 'bitch', 'bitcoin', 'bite', 'bjp', 'black', 'blackberry', 'blacklivesmatter', 'blackpool', 'blake', 'blame', 'blanket', 'blast', 'blaze', 'blazing', 'bleed', 'bleeding', 'bless', 'blessing', 'blight', 'blind', 'blink', 'blizzard', 'blizzarddraco', 'blizzheroe', 'blk', 'block', 'blocking', 'blog', 'blood', 'bloody', 'bloomberg', 'blow', 'blowout', 'blue', 'bluejay', 'blueprint', 'blunt', 'blutz10', 'blvd', 'bmw', 'board', 'boat', 'bob', 'body', 'boeing', 'boko', 'bolster', 'bomb', 'bomber', 'bombing', 'bone', 'book', 'bookboost', 'boom', 'boot', 'border', 'boss', 'boston', 'both', 'bother', 'bottle', 'bottom', 'boundary', 'bounty', 'bout', 'bowl', 'bowling', 'box', 'boxer', 'boy', 'boyfriend', 'bp', 'bradleybrad47', 'brady', 'brain', 'brake', 'brand', 'brave', 'brazil', 'brazilian', 'break', 'breakfast', 'breakingnew', 'breathe', 'breathing', 'breed', 'brick', 'bride', 'bridge', 'brief', 'bring', 'brit', 'britain', 'british', 'britishbakeoff', 'britney', 'bro', 'broad', 'broadway', 'brock', 'broken', 'bronx', 'brooke', 'brooklyn', 'brother', 'brown', 'browser', 'bruh', 'brutally', 'bs', 'btw', 'btwn', 'bu', 'buddy', 'buddys', 'budget', 'buff', 'buffalo', 'buffer', 'bug', 'build', 'building', 'bullet', 'bulletin', 'bully', 'bunch', 'bundle', 'burn', 'burning', 'burst', 'bus', 'bush', 'business', 'businessman', 'busy', 'but', 'butt', 'butter', 'butterfinger', 'button', 'buy', 'by', 'bypass', 'c130', 'ca', 'cabin', 'cable', 'cadfyi', 'caesar', 'cain', 'cake', 'calamity', 'calgary', 'calif', 'california', 'call', 'calm', 'calorie', 'cam', 'cameroon', 'camp', 'campaign', 'campfire', 'campus', 'can', 'canaanite', 'canada', 'cancel', 'cancer', 'candle', 'candy', 'cannon', 'canyon', 'cap', 'capacity', 'capital', 'capsize', 'captain', 'capture', 'car', 'card', 'care', 'career', 'careful', 'careless', 'cargo', 'carlos', 'carry', 'carryi', 'cart', 'cartoon', 'cas', 'case', 'cast', 'castle', 'casualty', 'cat', 'catastrophe', 'catastrophic', 'catch', 'catfish', 'cause', 'caution', 'cave', 'cawx', 'cbs', 'cdc', 'cdcgov', 'cdt', 'cecilthelion', 'cell', 'census', 'center', 'central', 'centre', 'ceo', 'certain', 'certainly', 'certificate', 'ch4', 'chain', 'chair', 'challenge', 'championship', 'chan', 'chance', 'change', 'channel', 'chaos', 'character', 'charge', 'charger', 'charity', 'charlie', 'charlotte', 'chart', 'chase', 'chat', 'chattanooga', 'cheat', 'check', 'cheese', 'chelsea', 'chem', 'chemical', 'cherokee', 'cherry', 'chesttorso', 'chevy', 'chew', 'cheyenne', 'chicago', 'chicagoarea', 'chief', 'chiefs', 'child', 'childhood', 'chile', 'chill', 'china', 'chinese', 'chocolate', 'choice', 'choke', 'choose', 'chp', 'chris', 'christ', 'christian', 'christie', 'christmas', 'chronicle', 'church', 'cia', 'cigarette', 'cindy', 'cinema', 'circle', 'circuit', 'circus', 'city', 'cityofcalgary', 'civil', 'civilian', 'civilization', 'cjoyner', 'cladding', 'claim', 'clash', 'class', 'classic', 'cld', 'clean', 'cleanup', 'clear', 'clearedincident', 'clearly', 'cleric', 'cleveland', 'click', 'client', 'cliff', 'climate', 'climb', 'clinton', 'clip', 'close', 'closed', 'closure', 'clothe', 'cloud', 'clown', 'club', 'clueless', 'clutch', 'cm', 'cnbc', 'cnn', 'co', 'coach', 'coal', 'coast', 'coastal', 'coaster', 'coat', 'cobra', 'cock', 'cod', 'code', 'coffee', 'cofounder', 'coil', 'coincide', 'cold', 'collapse', 'collection', 'collective', 'collide', 'collision', 'collision1141', 'collisionno', 'collude', 'color', 'colorado', 'colour', 'columbia', 'combat', 'combo', 'combust', 'come', 'comedy', 'command', 'commence', 'comment', 'commerce', 'commercial', 'commit', 'common', 'commonwealth', 'community', 'commute', 'comp', 'company', 'comparison', 'compete', 'complaint', 'complete', 'completely', 'complex', 'compliant', 'compound', 'computer', 'con', 'concept', 'concern', 'concerned', 'concert', 'conclude', 'conclusively', 'condemn', 'condemnation', 'condition', 'condo', 'condolence', 'conference', 'confirm', 'confirmation', 'conflict', 'congress', 'connector', 'connectorconnecto', 'conquest', 'consequence', 'consider', 'constant', 'constantly', 'construction', 'contact', 'contain', 'contemplate', 'content', 'context', 'continually', 'continue', 'continued', 'contract', 'control', 'conversation', 'convert', 'cook', 'cool', 'cop', 'cope', 'copilot', 'cops', 'copycat', 'cord', 'core', 'corleonedaboss', 'corner', 'correct', 'correction', 'cos', 'cosponsor', 'cost', 'costlier', 'costly', 'cotton', 'could', 'counselor', 'count', 'counter', 'country', 'county', 'couple', 'course', 'court', 'cousin', 'cover', 'cow', 'coworker', 'coyote', 'cr', 'crack', 'crackdown', 'cramer', 'crane', 'crap', 'crash', 'crater', 'crazy', 'cream', 'create', 'credit', 'cree', 'creep', 'crematoria', 'crew', 'cricket', 'crime', 'criminal', 'crisis', 'critical', 'croat', 'cross', 'crosse', 'crowd', 'crown', 'crude', 'crush', 'cruz', 'cry', 'cryptic', 'crystal', 'cs', 'ct', 'cta', 'cuban', 'cue', 'cuff', 'cum', 'cunt', 'cup', 'cupcake', 'curb', 'cure', 'curfew', 'current', 'currently', 'curse', 'curve', 'custer', 'custom', 'customer', 'cut', 'cute', 'cuz', 'cyber', 'cycle', 'cyclist', 'cyclone', 'cyprus', 'da', 'dad', 'daesh', 'daily', 'dailykos', 'dallas', 'dam', 'damage', 'damn', 'dan', 'dance', 'danger', 'dangerous', 'daniel', 'danisnotonfire', 'dannyonpc', 'dante', 'dare', 'dark', 'darkness', 'darude', 'date', 'datum', 'daughter', 'david', 'davidcameron', 'davidvonderhaar', 'day', 'dc', 'de', 'deactivate', 'dead', 'deadly', 'deal', 'dear', 'death', 'debate', 'debatequestionswewanttohear', 'debris', 'debt', 'decade', 'december', 'decide', 'decision', 'deck', 'declaration', 'declare', 'decline', 'decor', 'decrease', 'deed', 'deep', 'def', 'defeat', 'defect', 'defense', 'define', 'definitely', 'degree', 'delay', 'delete', 'deliver', 'deluge', 'dem', 'demand', 'democracy', 'democrats', 'demolish', 'demolition', 'demon', 'demonstratio', 'denmark', 'denver', 'deny', 'department', 'dependency', 'deploy', 'dept', 'depth', 'deputy', 'derail', 'derailment', 'derby', 'describe', 'description', 'desert', 'deserve', 'design', 'desire', 'desolate', 'desolation', 'despair', 'destiny', 'destroy', 'destroyer', 'destruction', 'destructive', 'detail', 'detain', 'detectado', 'determine', 'detonate', 'detonation', 'detour', 'detroit', 'devalue', 'devastate', 'devastated', 'devastation', 'develop', 'device', 'devil', 'di', 'diablo', 'diamond', 'diamondkesawn', 'dick', 'dickhead', 'die', 'diesis', 'diet', 'diff', 'difference', 'different', 'dig', 'digital', 'dignity', 'dinner', 'dip', 'diplomacy', 'direction', 'directioner', 'director', 'dis', 'disappear', 'disappoint', 'disaster', 'disco', 'discover', 'discovery', 'discuss', 'discussion', 'disea', 'disease', 'disney', 'displace', 'display', 'disrupt', 'disruptive', 'diss', 'distance', 'distinct', 'diver', 'diverse', 'divert', 'diving', 'division', 'djicemoon', 'dk', 'dm', 'dnb', 'do', 'dock', 'doctor', 'document', 'dog', 'dollar', 'dolphin', 'domain', 'domestic', 'don', 'donald', 'donate', 'door', 'dope', 'dopey', 'dorret', 'double', 'doublecups', 'doubt', 'douchebag', 'doug', 'down', 'download', 'downtown', 'dozen', 'dq', 'dr', 'drag', 'dragon', 'drain', 'drake', 'dramatic', 'draw', 'dream', 'dress', 'drift', 'drill', 'drink', 'drinking', 'drive', 'driver', 'driving', 'droid', 'drone', 'drop', 'drought', 'drown', 'drowning', 'drug', 'drum', 'drunk', 'dry', 'dryer', 'dt', 'dtn', 'dublin', 'dubstep', 'dude', 'due', 'dust', 'dutch', 'duty', 'dvc', 'dvd', 'each', 'ear', 'early', 'earn', 'earner', 'earning', 'earth', 'earthquake', 'easily', 'east', 'eastbound', 'easy', 'eat', 'eb', 'ebay', 'ebola', 'economic', 'economy', 'eden', 'edinburgh', 'edit', 'edition', 'editor', 'editorial', 'edm', 'edt', 'education', 'ee', 'effect', 'effort', 'egg', 'ego', 'egypt', 'eh', 'eight', 'either', 'el', 'elbow', 'election', 'electric', 'electrical', 'electro', 'electrocute', 'electronic', 'elem', 'elephant', 'elevate', 'elite', 'else', 'em', 'email', 'embroider', 'emerg', 'emerge', 'emergency', 'emmerdale', 'emotion', 'emotional', 'emotionally', 'empire', 'empty', 'emsc', 'en', 'enable', 'enact', 'encore', 'encounter', 'encourage', 'encouragement', 'end', 'endorse', 'enemy', 'energy', 'engage', 'engine', 'england', 'english', 'engulf', 'engulfed', 'engvaus', 'enhance', 'enjoy', 'enough', 'enroute', 'enrt', 'ensure', 'enter', 'entertainment', 'entire', 'enugu', 'environment', 'environmental', 'envw98', 'ep', 'epic', 'epicenter', 'epicentre', 'epidemic', 'episode', 'eq', 'equate', 'equipment', 'er', 'ergo', 'erode', 'error', 'eruption', 'es', 'escape', 'esh', 'especially', 'estate', 'esteem', 'estimate', 'et', 'etc', 'eu', 'europe', 'european', 'eurotunnel', 'evacuate', 'evacuation', 'evade', 'evanston', 'even', 'evening', 'event', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everywhere', 'evidence', 'evil', 'evolve', 'ex', 'exacerbate', 'exactly', 'examine', 'example', 'excellent', 'except', 'exchange', 'excite', 'excited', 'excitement', 'excuse', 'executive', 'exercise', 'exist', 'existence', 'exit', 'exp', 'expand', 'expect', 'expensive', 'experience', 'experiment', 'expert', 'explain', 'explode', 'exploit', 'exploration', 'explore', 'explosion', 'explosionproof', 'expose', 'exposure', 'express', 'extend', 'extension', 'external', 'extra', 'extreme', 'extremely', 'eye', 'eyewitness', 'faan', 'fabric', 'face', 'facebook', 'facility', 'fact', 'factor', 'factory', 'fade', 'fail', 'failure', 'fair', 'fairy', 'fake', 'falcon', 'fall', 'fallacy', 'false', 'fam', 'family', 'famine', 'famous', 'fan', 'fantastic', 'fantasy', 'far', 'farm', 'faroeisland', 'farrakhan', 'fart', 'fashion', 'fashionable', 'fast', 'fat', 'fatal', 'fatality', 'fatalityus', 'fate', 'father', 'faux', 'favor', 'favorite', 'favourite', 'favs', 'fb', 'fbi', 'fd', 'fear', 'feast', 'feat', 'feature', 'federal', 'fedex', 'fee', 'feed', 'feel', 'feelin', 'feeling', 'feinstein', 'female', 'feminist', 'fence', 'fennovoima', 'ferguson', 'ferry', 'festival', 'fettilootch', 'fevwarrior', 'few', 'fewmoretweet', 'field', 'fifth', 'fight', 'fighter', 'figure', 'file', 'fill', 'film', 'final', 'finally', 'financial', 'find', 'fine', 'finger', 'finish', 'finnish', 'fire', 'firefighter', 'fireman', 'firework', 'firey', 'first', 'fish', 'fishing', 'fist', 'fit', 'fitness', 'five', 'fix', 'fkn', 'flag', 'flame', 'flash', 'flat', 'flatten', 'flee', 'fleet', 'flight', 'flip', 'float', 'flood', 'flooding', 'floor', 'florida', 'flow', 'floyds', 'fly', 'fm', 'focus', 'fog', 'folk', 'follow', 'follower', 'food', 'foodscare', 'fool', 'foot', 'footage', 'football', 'for', 'forbe', 'forbes', 'forbid', 'force', 'ford', 'forecast', 'forest', 'forever', 'forget', 'forgive', 'forgot', 'form', 'former', 'fort', 'forth', 'fortune', 'forward', 'fossil', 'foster', 'foul', 'four', 'fourth', 'fox', 'foxnew', 'foxtrot', 'fr', 'fraction', 'fragile', 'fran', 'france', 'frank', 'franklin', 'freak', 'freakiest', 'free', 'freedom', 'freespeech', 'freestyle', 'freeway', 'freeze', 'french', 'fresh', 'friday', 'friend', 'friendship', 'friggin', 'frog', 'from', 'front', 'frontline', 'frontpage', 'fruit', 'ft', 'fte', 'fuck', 'fucking', 'fuel', 'fukushima', 'full', 'fully', 'fun', 'fund', 'funny', 'funtenna', 'fur', 'furious', 'future', 'fwy', 'fyi', 'ga', 'gabon', 'gadget', 'gain', 'galactic', 'gallipoli', 'gambit', 'game', 'gamergate', 'gang', 'garbage', 'garden', 'garfield', 'gas', 'gateau', 'gave', 'gay', 'gaza', 'gbbo', 'gd', 'gear', 'gel', 'geller', 'gem', 'general', 'generally', 'generation', 'geneva', 'genocide', 'genuine', 'george', 'georgia', 'gerenciatodo', 'germ', 'german', 'germany', 'get', 'gets', 'getting', 'gf', 'ghost', 'ghostwriter', 'giant', 'gift', 'gig', 'gilbert23', 'girl', 'girlfriend', 'give', 'glad', 'glass', 'glink', 'global', 'globalwarme', 'globe', 'gm', 'gmt', 'go', 'goal', 'goat', 'god', 'godslove', 'gofundme', 'going', 'gold', 'goldstein', 'golf', 'gon', 'good', 'goodbye', 'google', 'gop', 'gopdebate', 'gordon', 'gorgeous', 'got', 'gov', 'government', 'governor', 'govt', 'gp', 'grab', 'grabber', 'grace', 'grade', 'grain', 'grandeur', 'grandpa', 'grant', 'grass', 'grateful', 'gravel', 'gray', 'graze', 'great', 'greece', 'greek', 'green', 'greenway', 'greet', 'greg', 'grenade', 'grey', 'grief', 'grill', 'grind', 'ground', 'group', 'grove', 'grow', 'gt', 'gta', 'gtgt', 'gtgtgt', 'guarantee', 'guard', 'guardian', 'guess', 'guest', 'guide', 'guillermo', 'gum', 'gun', 'gunfire', 'gunman', 'gunsense', 'gunshot', 'gust', 'gusty', 'guy', 'ha', 'habit', 'hack', 'hacker', 'hah', 'haha', 'hahah', 'hahaha', 'hahahah', 'hail', 'hailstorm', 'hair', 'haiyan', 'half', 'halifax', 'hamas', 'hamburg', 'hampshire', 'hand', 'handbag', 'handle', 'hang', 'happen', 'happily', 'happiness', 'happy', 'haram', 'harbor', 'hard', 'hardcore', 'hardline', 'harm', 'harmkid', 'harper', 'harry', 'harrybecareful', 'hasbro', 'hashtag', 'hat', 'hatcap', 'hate', 'have', 'hawaii', 'hazard', 'hazardous', 'hd', 'he', 'head', 'headline', 'heal', 'health', 'healthcare', 'healthy', 'hear', 'hearing', 'heart', 'hearthstone', 'heartless', 'heat', 'heaven', 'heavy', 'height', 'heights', 'helicopter', 'hell', 'hella', 'hellfire', 'hello', 'help', 'helping', 'helpline', 'her', 'here', 'hermancranston', 'hero', 'heroin', 'hey', 'hi', 'hide', 'hieroglyphic', 'high', 'highly', 'highway', 'hijack', 'hijacker', 'hijacking', 'hike', 'hiker', 'hilarious', 'hill', 'hillary', 'hip', 'hiphop', 'hire', 'hiroshima', 'his', 'historic', 'history', 'hit', 'hmm', 'hmu', 'hoax', 'hobbit', 'hobo', 'hoe', 'hold', 'holiday', 'holland', 'hollywood', 'holmgren', 'holy', 'home', 'homeless', 'honestly', 'honey', 'honor', 'hood', 'hooligan', 'hop', 'hope', 'hopefully', 'horn', 'horrible', 'horrific', 'horror', 'horse', 'hospital', 'host', 'hostage', 'hostageamp2', 'hostages', 'hot', 'hotel', 'hour', 'house', 'household', 'housing', 'houston', 'how', 'however', 'huffman', 'huge', 'hughe', 'hughes', 'huh', 'human', 'humanconsumption', 'humanity', 'humble', 'humidity', 'hundred', 'hunger', 'hungry', 'hunk', 'hunt', 'hunter', 'hurricane', 'hurricanedolce', 'hurry', 'hurt', 'hwo', 'hwy', 'hybrid', 'hype', 'hypocrisy', 'hysteria', 'i10', 'i405', 'i5', 'i77', 'ian', 'ianhellfire', 'ibooklove', 'ice', 'icemoon', 'ices', 'icymi', 'idc', 'idea', 'idfire', 'idis', 'idk', 'idol', 'idp', 'idps', 'ie', 'if', 'ig', 'iger', 'ignite', 'ignition', 'ignore', 'ihhen', 'ii', 'iii', 'ik', 'ill', 'illegal', 'illinois', 'im', 'image', 'imagine', 'imdb', 'immediately', 'impact', 'imperfect', 'import', 'impossible', 'impressed', 'impressive', 'imprison', 'improve', 'improvement', 'impulse', 'in', 'incase', 'inch', 'incident', 'include', 'increase', 'incredible', 'indeed', 'independent', 'india', 'indian', 'indifference', 'individual', 'indonesia', 'industry', 'inec', 'inevitable', 'inevitably', 'inferno', 'info', 'information', 'infosec', 'inj', 'injure', 'injury', 'injuryi495', 'ink', 'inmate', 'inner', 'inning', 'innocent', 'innovation', 'insane', 'inside', 'insight', 'inst', 'instagram', 'installation', 'instant', 'instantly', 'instead', 'instruction', 'insurance', 'insurer', 'intact', 'intensity', 'interest', 'interested', 'interesting', 'intern', 'internal', 'internally', 'international', 'internet', 'intersection', 'interstate', 'interview', 'into', 'intrigue', 'introduce', 'inundate', 'inundation', 'invade', 'invalid', 'invasion', 'invest', 'investigate', 'investigation', 'investigator', 'invite', 'invoice', 'involve', 'iphone', 'ipod', 'ir', 'iran', 'irandeal', 'iranian', 'iranians', 'iraq', 'iredell', 'ireland', 'irish', 'ironic', 'irony', 'irvine', 'isis', 'islam', 'islamic', 'island', 'israel', 'israeli', 'issue', 'it', 'italian', 'italy', 'item', 'its', 'itune', 'ja', 'jack', 'jacket', 'jackson', 'jacksonville', 'jail', 'jam', 'jamaica', 'jamaicaplain', 'james', 'jan', 'japan', 'japanese', 'japans', 'japìn', 'jar', 'jax', 'jay', 'jdabe80', 'jealous', 'jean', 'jeb', 'jedi', 'jeff', 'jerry', 'jersey', 'jesus', 'jet', 'jewish', 'jim', 'jimmyfallon', 'job', 'joe', 'joel', 'johannesburg', 'john', 'johnson', 'join', 'joint', 'joke', 'jon', 'jonathan', 'jonathanferrell', 'jones', 'jones94kyle', 'jonvoyage', 'jordan', 'journalism', 'journalist', 'joy', 'jr', 'jst', 'judge', 'juice', 'julie', 'juliedicaro', 'july', 'jump', 'just', 'justice', 'justify', 'justin', 'justinbieber', 'justmarrie', 'kaduna', 'kalle', 'kanye', 'karachi', 'karma', 'kashmir', 'katherine', 'katrina', 'kca', 'keep', 'kenya', 'keratin', 'kerricktrial', 'kerry', 'key', 'kick', 'kid', 'kidnap', 'kids', 'kill', 'killer', 'killing', 'kind', 'kinda', 'kindermorgan', 'kindle', 'king', 'kingdom', 'kiss', 'kit', 'kitten', 'km', 'knee', 'knife', 'knob', 'knock', 'know', 'koin6news', 'korea', 'kowing', 'ks', 'ks94', 'kurd', 'kurdish', 'kurtschlichter', 'kuwait', 'ky', 'kyle', 'la', 'lab', 'label', 'lack', 'laden', 'lady', 'lake', 'lamp', 'land', 'landfall', 'landing', 'landscape', 'landslide', 'lane', 'langley', 'language', 'lansdowne', 'large', 'last', 'late', 'lately', 'later', 'latestnews', 'latime', 'laugh', 'launch', 'laundry', 'lauren', 'lava', 'lavenderpoetrycafe', 'law', 'lay', 'layout', 'lead', 'leader', 'leadership', 'league', 'leak', 'learn', 'least', 'leather', 'leave', 'lee', 'leg', 'legacy', 'legal', 'legio', 'legion', 'legionnaire', 'legislation', 'lego', 'leisure', 'lemon', 'leo', 'lesbian', 'less', 'lesson', 'let', 'lethal', 'letter', 'level', 'lez', 'lgbt', 'lglorg', 'liberty', 'library', 'libya', 'license', 'lie', 'life', 'lifestyle', 'lifethreatening', 'lift', 'lifting', 'light', 'lighten', 'lighting', 'lightning', 'like', 'likely', 'lil', 'limit', 'limited', 'line', 'link', 'linkury', 'lion', 'lionel', 'lip', 'list', 'listen', 'listenlive', 'literally', 'little', 'live', 'living', 'lizard', 'll', 'lmao', 'lmfao', 'load', 'loading', 'loan', 'lobby', 'local', 'localarsonist', 'location', 'lock', 'locke', 'locker', 'locomotive', 'logan', 'logo', 'lol', 'london', 'londonfire', 'lone', 'lonewolffur', 'long', 'look', 'loop', 'loose', 'loot', 'looter', 'lord', 'lorry', 'los', 'lose', 'loss', 'lot', 'loud', 'louis', 'lous', 'love', 'lovely', 'low', 'lower', 'lowly', 'lownde', 'lrt', 'lt', 'lt3', 'luchaunderground', 'luck', 'lucky', 'luis', 'luka', 'lulgzimbestpict', 'lunch', 'lung', 'lyric', 'm194', 'mac', 'machine', 'mad', 'madhya', 'madinah', 'madison', 'magginoodle', 'magic', 'magnum', 'mail', 'main', 'maintain', 'maintenance', 'maj', 'major', 'majority', 'make', 'maker', 'maketh', 'malaysia', 'malaysian', 'male', 'malik', 'mall', 'mama', 'mamata', 'man', 'manage', 'management', 'manager', 'manchester', 'manmade', 'mansehra', 'mansion', 'manslaughter', 'manutd', 'many', 'map', 'maria', 'marians', 'marine', 'mark', 'marker', 'market', 'marketforce', 'martinmj22', 'marvel', 'mary', 'maryland', 'mass', 'massacre', 'massive', 'massmurderer', 'master', 'mat', 'match', 'material', 'matter', 'matthew', 'mattson', 'max', 'maximum', 'may', 'mayan', 'maybe', 'mayhem', 'md', 'meal', 'mean', 'measurement', 'meat', 'meatloving', 'mechanical', 'med', 'medal', 'media', 'medic', 'medical', 'medicine', 'medieval', 'mediterran', 'mediterranean', 'medium', 'meek', 'meet', 'meeting', 'mega', 'melt', 'meltdown', 'member', 'meme', 'memorial', 'memorie', 'memories', 'memory', 'memphis', 'men', 'mens', 'mentally', 'mention', 'mercado', 'mercy', 'mess', 'message', 'messenger', 'messi', 'met', 'metal', 'meter', 'method', 'metlife', 'metric', 'metro', 'metrofmtalk', 'mexico', 'mf', 'mfs', 'mh370', 'mhtw4fnet', 'miami', 'mic', 'michael', 'michelebachman', 'michigan', 'microlight', 'microsoft', 'middle', 'midget', 'midnight', 'mido', 'might', 'migrant', 'mike', 'mikeparractor', 'mile', 'militant', 'military', 'milkshake', 'mill', 'million', 'min', 'mind', 'mine', 'minecraft', 'miner', 'mineral', 'minhazmerchant', 'mini', 'minimehh', 'mining', 'minion', 'minister', 'minor', 'minority', 'minute', 'mirage', 'misery', 'mishacollin', 'mishap', 'miss', 'missile', 'mission', 'missionhill', 'mississauga', 'mistake', 'mitigation', 'mitt', 'mix', 'miyagi', 'ml', 'mlb', 'mma', 'mmmmmm', 'mnpdnashville', 'mo', 'mod', 'mode', 'model', 'modernize', 'modi', 'modify', 'modiministry', 'mohammed', 'mom', 'moment', 'mon', 'money', 'monkey', 'monogram', 'monster', 'montetjwitter11', 'month', 'mood', 'moon', 'moore', 'mooresville', 'mop', 'moral', 'more', 'morgan', 'morning', 'mosque', 'mosquito', 'most', 'moth', 'mother', 'motion', 'motivation', 'motor', 'motorcraft', 'motorcycle', 'motorcyclist', 'mount', 'mountain', 'mountaineer', 'mourning', 'mouth', 'move', 'movement', 'movie', 'mp', 'mph', 'mr', 'ms', 'msf', 'mt', 'mtvhottest', 'much', 'mud', 'mudslide', 'mullah', 'multiplayer', 'mum', 'mumbai', 'municipal', 'murder', 'murderer', 'murderous', 'murfreesboro', 'muscle', 'museum', 'music', 'musician', 'muslim', 'muslims', 'must', 'mutant', 'mutual', 'mv', 'my', 'myanmar', 'myself', 'mystery', 'na', 'nagasaki', 'nah', 'nail', 'name', 'nan', 'nap', 'narendramodi', 'nasa', 'nasahurricane', 'nashville', 'nasty', 'nation', 'national', 'native', 'nato', 'natural', 'nature', 'naval', 'navbl', 'nave', 'navy', 'nazi', 'nb', 'nc', 'nd', 'ne', 'near', 'nearby', 'nearly', 'neck', 'need', 'negative', 'negros', 'neighbor', 'neighborhood', 'neighbour', 'neil', 'neither', 'nema', 'nestleindia', 'network', 'never', 'new', 'newlywed', 'news', 'newsintweet', 'newswatch', 'newyork', 'next', 'nfl', 'niall', 'nice', 'nickcocofree', 'niece', 'nigeria', 'nigerian', 'nigga', 'niggas', 'night', 'nightmare', 'nike', 'nikeplus', 'nine', 'nj', 'nm', 'no', 'noahanyname', 'nobody', 'noise', 'non', 'noncompliant', 'none', 'noonancindynoonanheartbreak', 'normal', 'north', 'northeast', 'northern', 'nose', 'nosurrend', 'not', 'note', 'nothing', 'notice', 'notification', 'novel', 'november', 'now', 'nowhere', 'nowplaye', 'nowplaying', 'np', 'nri', 'ntsb', 'nu', 'nuclear', 'nude', 'nugget', 'nuke', 'number', 'nurse', 'nursing', 'nut', 'nw', 'nwo', 'nws', 'ny', 'nyc', 'nylon', 'nytime', 'o784', 'oak', 'obama', 'obispo', 'object', 'obliterate', 'obliteration', 'oc', 'occasion', 'occupant', 'occur', 'ocean', 'odd', 'odeon', 'of', 'off', 'offensive', 'offensiveåêcontent', 'offer', 'offers2go', 'office', 'officer', 'official', 'officially', 'offroad', 'often', 'oh', 'ohio', 'oil', 'ok', 'okanagan', 'okay', 'oklahoma', 'oklahomaok', 'okwx', 'old', 'oliver', 'olympic', 'omar', 'omg', 'on', 'once', 'one', 'online', 'onlinecommunitie', 'only', 'ontario', 'onto', 'ooh', 'oooh', 'oooooohhhh', 'oop', 'op', 'open', 'opening', 'openly', 'oper', 'operation', 'opinion', 'opp', 'opposite', 'opposition', 'oppression', 'option', 'opus', 'or', 'oral', 'orange', 'order', 'oregon', 'org', 'organization', 'ori', 'origin', 'original', 'originalfunko', 'ornament', 'os', 'oth', 'other', 'otherwise', 'otrametlife', 'oun', 'our', 'out', 'outage', 'outbreak', 'outfit', 'outflow', 'outlook', 'outrage', 'outside', 'ouvindo', 'over', 'overload', 'overlook', 'overnight', 'own', 'owner', 'pa', 'pace', 'pacific', 'pack', 'pad', 'page', 'pain', 'paint', 'pair', 'pak', 'pakistan', 'pakistani', 'palermo', 'palestine', 'palestinian', 'palestinians', 'palin', 'palm', 'pam', 'pamela', 'pancake', 'pandemonium', 'panel', 'panic', 'pant', 'pantherattack', 'paper', 'parade', 'paramedic', 'parent', 'parenthood', 'park', 'parker', 'parking', 'parleys', 'parole', 'part', 'participate', 'partner', 'party', 'pass', 'passenger', 'password', 'past', 'patch', 'path', 'pathogen', 'patience', 'patient', 'patrick', 'pattern', 'paul', 'pave', 'pay', 'pbban', 'pc', 'pcp', 'pdp', 'pdx911', 'peace', 'peaceful', 'peacefully', 'peak', 'peanut', 'pedestrian', 'peep', 'penalty', 'pendleton', 'pennington', 'penny', 'people', 'pepper', 'percent', 'perfect', 'perhaps', 'period', 'perquisite', 'person', 'personal', 'personally', 'personnel', 'pertain', 'pet', 'peterjuke', 'petition', 'pharaoh', 'phase', 'phew', 'phil', 'philadelphia', 'philippine', 'philippines', 'phillip', 'philly', 'phoenix', 'phone', 'photo', 'photograph', 'photographer', 'photography', 'photoshop', 'physical', 'physician', 'pic', 'pick', 'picking', 'pickup', 'picture', 'piece', 'pierce', 'pile', 'pileup', 'pill', 'pilot', 'piner', 'pinpoint', 'pipeline', 'pit', 'pitch', 'pitcher', 'pizza', 'pkk', 'pkwy', 'place', 'plague', 'plain', 'plan', 'plane', 'planet', 'planned', 'planning', 'plant', 'plastic', 'plate', 'platform', 'play', 'player', 'playing', 'playlist', 'playoff', 'playstation', 'please', 'pledge', 'plot', 'pls', 'plug', 'plummet', 'plunging', 'plus', 'pm', 'pocket', 'point', 'pol', 'poland', 'police', 'policerun', 'policy', 'politic', 'political', 'politifiact', 'poll', 'pomo', 'pond', 'pool', 'poor', 'pop', 'pope', 'popular', 'population', 'porn', 'port', 'portion', 'portland', 'positive', 'possible', 'possibly', 'post', 'potential', 'potentially', 'potus', 'pound', 'pour', 'pov', 'poverty', 'power', 'powerful', 'powerline', 'ppl', 'prabhu', 'practice', 'pradesh', 'pray', 'prayer', 'pre', 'prebreak', 'precipitation', 'predict', 'prediction', 'prefer', 'pregnant', 'premature', 'premium', 'premonition', 'preorder', 'prepare', 'prepared', 'preparedness', 'presence', 'present', 'preservation', 'president', 'press', 'pressure', 'pretend', 'pretty', 'prevent', 'prevention', 'previous', 'previously', 'prez', 'price', 'priest', 'primary', 'prime', 'prince', 'print', 'prior', 'priority', 'prison', 'private', 'pro', 'prob', 'probably', 'probe', 'problem', 'procedure', 'prod', 'produce', 'product', 'professional', 'profile', 'program', 'programme', 'progress', 'progressive', 'project', 'promise', 'prompt', 'prone', 'proof', 'property', 'propertycasualty', 'prophet', 'prophetmuhammad', 'prosecute', 'protect', 'protector', 'protest', 'proud', 'prove', 'provide', 'providence', 'provoke', 'ps', 'psychiatric', 'psychological', 'pt', 'ptbo', 'ptsd', 'ptsdchat', 'public', 'publish', 'pull', 'pump', 'pumpkin', 'pun', 'pundit', 'punish', 'punishment', 'punjab', 'puppy', 'purchase', 'purple', 'purse', 'push', 'pussy', 'put', 'putin', 'quake', 'quality', 'quarantine', 'quarantined', 'quarrel', 'quarter', 'quartz', 'que', 'queen', 'quest', 'question', 'quick', 'quickly', 'quite', 'quiz', 'quote', 'quran', 'race', 'radar', 'radiation', 'radio', 'radioactive', 'rage', 'raid', 'raider', 'rail', 'railway', 'rain', 'rainfall', 'rainstorm', 'rally', 'ramag', 'random', 'range', 'rank', 'rap', 'rape', 'rapidcity', 'rapidly', 'rapper', 'rare', 'rate', 'rather', 'rating', 'ray', 'raynbowaffair', 'raze', 'rd', 'rdhorndale', 're', 'rea', 'reach', 'react', 'reactor', 'read', 'reading', 'ready', 'real', 'realdonaldtrump', 'realise', 'reality', 'realization', 'realize', 'really', 'realtime', 'reap', 'rear', 'reason', 'recall', 'recap', 'receive', 'recent', 'recently', 'reckless', 'recognize', 'recommend', 'record', 'recount', 'recover', 'recovery', 'recycle', 'red', 'reddit', 'redeemeth', 'rediscover', 'reduce', 'refer', 'reflect', 'refugee', 'refugio', 'refuse', 'regard', 'regardless', 'region', 'regional', 'register', 'regret', 'regular', 'reid', 'reject', 'relate', 'related', 'relationship', 'relative', 'relax', 'release', 'relief', 'relive', 'remain', 'remember', 'remind', 'reminder', 'remorse', 'removal', 'remove', 'render', 'rene', 'renew911health', 'reno', 'reopen', 'rep', 'repair', 'repatriate', 'repeat', 'replace', 'report', 'reportedly', 'reporting', 'represent', 'republican', 'republicans', 'request', 'require', 'rescue', 'rescuer', 'research', 'reserve', 'reshape', 'resident', 'residential', 'respect', 'respond', 'responder', 'response', 'responsibility', 'responsible', 'rest', 'restaurant', 'restore', 'restrict', 'result', 'retail', 'return', 'retweet', 'reunion', 'reuter', 'reuters', 'reveal', 'revelation', 'revenue', 'review', 'revolution', 'reward', 'rexyy', 'rey', 'rice', 'richard', 'richmond', 'rick', 'rickperry', 'rid', 'ride', 'rider', 'ridge', 'ridiculous', 'rifle', 'right', 'rihanna', 'ring', 'rio', 'riot', 'rioter', 'rioting', 'rip', 'rise', 'risk', 'river', 'riyadh', 'rly', 'rn', 'road', 'roanoke', 'rob', 'robert', 'robinson', 'robot', 'robotrainstorm', 'rock', 'rocket', 'rocky', 'rockyfire', 'roger', 'rohingya', 'rohnertparkdps', 'role', 'roll', 'roller', 'rolling', 'romance', 'rome', 'ronaldo', 'roof', 'room', 'roosevelt', 'root', 'ross', 'rossum', 'roster', 'rotation', 'round', 'route', 'royal', 'royalcarribean', 'rt', 'rtamerica', 'rubber', 'rubble', 'rudd', 'ruin', 'rule', 'run', 'runner', 'running', 'runway', 'rush', 'russia', 'russian', 'rutherford', 'rwy', 'ryan', 'rì', 's2', 'sa', 'sac', 'sacramento', 'sad', 'saddlebrooke', 'sadly', 'safe', 'safely', 'safety', 'sail', 'sailing', 'saipan', 'sake', 'sale', 'salem', 'salmon', 'salt', 'salvador', 'salvation', 'samanthaturne19', 'samaritans', 'same', 'sample', 'san', 'sanction', 'sand', 'sandiego', 'sandstorm', 'sandy', 'santa', 'sarah', 'sarcasm', 'sassy', 'satan', 'satchel', 'satellite', 'saturday', 'saudi', 'save', 'savebee', 'saving', 'say', 'sb', 'scale', 'scare', 'scared', 'scariest', 'scary', 'scene', 'schedule', 'scheme', 'schiphol', 'school', 'science', 'scientist', 'scoopit', 'score', 'scotland', 'scott', 'scratch', 'scream', 'screamqueens', 'screen', 'screenshot', 'screw', 'scuf', 'se', 'sea', 'seal', 'search', 'season', 'seat', 'seattle', 'second', 'secret', 'section', 'secure', 'security', 'see', 'seek', 'seeker', 'seem', 'seismic', 'seize', 'select', 'selection', 'self', 'selfie', 'selfimage', 'senate', 'senator', 'send', 'senior', 'sense', 'sensor', 'sensorsenso', 'sentinel', 'sep', 'september', 'serial', 'series', 'serious', 'seriously', 'servant', 'serve', 'server', 'service', 'set', 'seven', 'several', 'severe', 'sex', 'sexual', 'sexy', 'sf', 'sh', 'shadow', 'shake', 'shaker', 'shall', 'shame', 'shanghai', 'shape', 'share', 'sharethis', 'shark', 'sharp', 'she', 'sheer', 'sheet', 'shelby', 'shelter', 'shepherd', 'shia', 'shift', 'ship', 'shipwreck', 'shira', 'shirt', 'shit', 'shizune', 'shock', 'shoot', 'shooter', 'shooting', 'shop', 'short', 'shot', 'should', 'shoulder', 'shout', 'show', 'showcase', 'shower', 'shut', 'shutdown', 'si', 'sible', 'sicily', 'sick', 'side', 'sideline', 'sigalert', 'sight', 'sign', 'silence', 'silent', 'silver', 'silvergray', 'simple', 'simply', 'simulate', 'simulation', 'simultaneous', 'sin', 'since', 'sing', 'singe', 'single', 'sinjar', 'sink', 'sinkhole', 'sinking', 'sir', 'siren', 'sis', 'sismo', 'sister', 'sit', 'site', 'sitting', 'sittwe', 'situation', 'six', 'sixmeter', 'sixth', 'size', 'skanndtyagi', 'sketch', 'skill', 'skim', 'skin', 'skinny', 'skip', 'skirt', 'sky', 'slam', 'slanglucci', 'slate', 'slayer', 'sleep', 'slicker', 'slide', 'slight', 'slightly', 'slip', 'slow', 'slowly', 'sm', 'small', 'smart', 'smash', 'smaug', 'smell', 'smh', 'smile', 'smithsonian', 'smoke', 'smoking', 'smoky', 'smooth', 'sn', 'snake', 'snap', 'snapchat', 'sneak', 'snipe', 'snow', 'snowball', 'snowstorm', 'so', 'soak', 'soccer', 'social', 'socialism', 'socialnew', 'society', 'soft', 'solar', 'soldier', 'solid', 'solo', 'solution', 'solve', 'somalia', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometimes', 'son', 'song', 'sony', 'soon', 'sooo', 'soooo', 'sophie', 'sorrow', 'sorry', 'sort', 'soudelor', 'soul', 'sound', 'soundcloud', 'source', 'south', 'southampton', 'southbound', 'southdown', 'southeast', 'southern', 'soviet', 'sp', 'space', 'spaceship', 'spain', 'spanish', 'spark', 'speak', 'speaker', 'spear', 'special', 'specialist', 'specially', 'specie', 'specif', 'specific', 'specimen', 'spectacular', 'speed', 'spell', 'spencer', 'spend', 'spider', 'spill', 'spin', 'spinningbot', 'spirit', 'split', 'sponsor', 'sport', 'sportwatch', 'spos', 'spot', 'spray', 'spread', 'spring', 'sprinter', 'spur', 'sputnik', 'squad', 'square', 'squeeze', 'squirrel', 'ssw', 'st', 'stab', 'stadium', 'staff', 'stage', 'stamp', 'stand', 'standard', 'standus', 'star', 'stars', 'start', 'starter', 'startup', 'starve', 'stat', 'state', 'statement', 'states', 'station', 'status', 'stay', 'steal', 'steam', 'steel', 'stem', 'step', 'stephen', 'steve', 'stewart', 'stick', 'still', 'stir', 'sto', 'stock', 'stomach', 'stone', 'stop', 'store', 'storm', 'story', 'stout', 'straight', 'strand', 'strange', 'strategicpatience', 'strategy', 'streak', 'stream', 'streaming', 'street', 'strengthen', 'stress', 'stretch', 'stretcher', 'stretcherbearer', 'strike', 'strikesstrike', 'strip', 'strong', 'strongly', 'structural', 'structure', 'struggle', 'strut', 'sts', 'stuart', 'student', 'studio', 'study', 'stuff', 'stupid', 'style', 'sub', 'subject', 'subreddit', 'such', 'suck', 'suddenly', 'sue', 'suffer', 'suicide', 'suit', 'summer', 'summerfate', 'summit', 'sun', 'sunday', 'sunk', 'sunny', 'sunset', 'super', 'supernatural', 'superstition', 'support', 'suppose', 'supreme', 'sure', 'surely', 'surf', 'surface', 'surfer', 'surge', 'surprise', 'surprised', 'surround', 'suruc', 'suruì', 'survey', 'survival', 'survive', 'survivor', 'suspect', 'suspend', 'suspense', 'sustainability', 'suv', 'sw', 'swallow', 'swallows', 'swansea', 'swarm', 'swear', 'sweep', 'sweet', 'sweet2young', 'swim', 'swimming', 'swing', 'switch', 'sws', 'sx', 'sydney', 'symphony', 'syndrome', 'syria', 'syrian', 'system', 'tab', 'table', 'tablet', 'taco', 'tag', 'taiwan', 'take', 'tale', 'talent', 'taliban', 'talk', 'talkin', 'talkradio', 'tampa', 'tank', 'tanzania', 'tape', 'target', 'task', 'taste', 'tattoo', 'tax', 'taxis', 'taxiway', 'taylor', 'tbt', 'tc', 'tcot', 'tdp', 'te', 'tea', 'teach', 'team', 'tear', 'tech', 'techesback', 'technica', 'technology', 'ted', 'tee', 'teen', 'tell', 'temp', 'temper', 'temple', 'temporary300', 'temptation', 'ten', 'tend', 'tension', 'tent', 'term', 'terrible', 'terrifying', 'terror', 'terrorism', 'terrorist', 'teslas', 'test', 'texas', 'text', 'tflbusalert', 'tgirl', 'th', 'than', 'thank', 'thankful', 'thankfully', 'thanku', 'that', 'the', 'theadvocatemag', 'theater', 'theatre', 'their', 'theme', 'then', 'theological', 'theory', 'therapy', 'there', 'these', 'they', 'thick', 'thigh', 'thin', 'thing', 'think', 'thinking', 'third', 'thirst', 'this', 'thisiswhywecanthavenicething', 'thisizbwright', 'tho', 'thomas', 'those', 'though', 'thought', 'thousand', 'threat', 'threaten', 'three', 'thriller', 'throat', 'throughout', 'throw', 'throwingknifes', 'thru', 'thu', 'thunder', 'thunderstorm', 'thur', 'thursday', 'thus', 'thx', 'ticket', 'tidal', 'tie', 'tiger', 'till', 'tilnow', 'time', 'time20150805', 'time20150806', 'timeline', 'times', 'timkaine', 'tin', 'tinyjecht', 'tip', 'tired', 'titanic', 'title', 'tmp', 'to', 'today', 'todd', 'toddler', 'toe', 'together', 'toilet', 'tokyo', 'toll', 'tom', 'tomorrow', 'ton', 'tonight', 'tonto', 'too', 'tool', 'tooth', 'top', 'torch', 'tornado', 'toronto', 'tory', 'total', 'totally', 'tote', 'touch', 'tough', 'tour', 'tournament', 'tow', 'toward', 'towards', 'towel', 'town', 'township', 'toxic', 'tr', 'trace', 'track', 'traditional', 'traffic', 'trafford', 'tragedy', 'tragic', 'trail', 'trailer', 'train', 'training', 'tram', 'trancy', 'transit', 'transport', 'trap', 'trapmusic', 'trash', 'trauma', 'traumatise', 'traumatised', 'travel', 'treat', 'treatment', 'tree', 'treeporn', 'tremor', 'trench', 'trend', 'trent', 'trfc', 'trial', 'tribal', 'trick', 'trigger', 'trip', 'triple', 'tripledigit', 'trolley', 'troop', 'tropical', 'trouble', 'troy', 'trs', 'trubgme', 'truck', 'true', 'truly', 'trump', 'trunk', 'trust', 'truth', 'try', 'tryna', 'ts', 'tsunami', 'tsunamiesh', 'tt', 'tte', 'tube', 'tubestrike', 'tumble', 'tune', 'turkey', 'turkish', 'turn', 'tv', 'tweet', 'tweetlikeitsseptember11th2001', 'twelve', 'twentynine', 'twia', 'twice', 'twin', 'twister', 'twitter', 'two', 'ty', 'type', 'typhoon', 'typhoondevastate', 'typo', 'tyre', 'uber', 'ud', 'udhampur', 'uganda', 'ugh', 'ugly', 'uk', 'ukraine', 'ultimalucha', 'ultimate', 'un', 'unavoidable', 'unawares', 'uncle', 'unconfirmed', 'under', 'undergroundrailraod', 'understand', 'unfold', 'uniform', 'union', 'unit', 'united', 'unity', 'universe', 'university', 'unknown', 'unless', 'unlock', 'unnecessary', 'unr', 'unrelenting', 'unsafe', 'unsuckdcmetro', 'unto', 'unveil', 'up', 'update', 'upgrade', 'upheaval', 'upon', 'upper', 'upset', 'ur', 'uranium', 'uribe', 'urs', 'us', 'us101', 'usa', 'usagov', 'usatoday', 'use', 'user', 'usgs', 'ushanka', 'usnwsgov', 'usual', 'usually', 'utc', 'utc20150805', 'utc5', 'utter', 'va', 'vabengal', 'vacant', 'val', 'valley', 'value', 'vampiro', 'van', 'vancouver', 'vanish', 'vantage', 'variety', 'various', 've', 'vegas', 'vegetable', 'vegetarian', 'vehicle', 'venice', 'verdict', 'version', 'very', 'vessel', 'vet', 'veteran', 'vgbootcamp', 'vi', 'via', 'vibrate', 'victim', 'victory', 'vid', 'video', 'vietnam', 'view', 'village', 'vine', 'vintage', 'vinyl', 'violation', 'violence', 'violent', 'vip', 'viralspell', 'virgin', 'visibility', 'vision', 'visit', 'vladimir', 'voice', 'volcano', 'volga', 'volunteer', 'vote', 'votejkt48id', 'voter', 'voting', 'vs', 'vuitton', 'vulnerable', 'wa', 'waimate', 'waist', 'wait', 'wake', 'walk', 'walker', 'wall', 'walmart', 'walter', 'wan', 'wannabe', 'want', 'wants', 'war', 'warcraft', 'warfighte', 'warm', 'warming', 'warn', 'warne', 'warning', 'warship', 'wash', 'washington', 'washingtonpost', 'waste', 'watch', 'water', 'waterresistant', 'watertown', 'waterway', 'wave', 'way', 'wayne', 'wbioterrorismampuse', 'wce', 'wd', 'we', 'weak', 'wealth', 'wealthy', 'weapon', 'wear', 'weather', 'website', 'wedding', 'wednesday', 'wee', 'weed', 'week', 'weekend', 'weekold', 'weigh', 'weight', 'weird', 'welcome', 'welfare', 'well', 'west', 'western', 'weston', 'wet', 'weyreygidi', 'wftv', 'whale', 'whao', 'what', 'whatever', 'whatsapp', 'wheavenly', 'wheel', 'when', 'where', 'whether', 'which', 'while', 'whip', 'whirlwind', 'whistle', 'white', 'whitehouse', 'who', 'whoa', 'whole', 'wholesale', 'whoop', 'wht', 'why', 'wi', 'wicked', 'wide', 'widespread', 'wife', 'wild', 'wildfire', 'will', 'williams', 'willing', 'win', 'wind', 'window', 'windstorm', 'windy', 'wine', 'wing', 'winston', 'winter', 'wipp', 'wire', 'wish', 'with', 'wither', 'within', 'without', 'witness', 'witter', 'wmata', 'wnd', 'wod', 'woke', 'wolf', 'wom', 'woman', 'women', 'wonder', 'wonderful', 'wood', 'word', 'work', 'worker', 'working', 'workplace', 'world', 'worldnew', 'worry', 'worstsummerjob', 'worth', 'would', 'wound', 'wow', 'wowo', 'wrap', 'wrapup', 'wreck', 'wreckage', 'wrist', 'write', 'writer', 'writing', 'wrong', 'wrought', 'wtf', 'ww1', 'wwi', 'wwii', 'wx', 'wy', 'xb1', 'xbox', 'xd', 'xp', 'xxx', 'ya', 'yahistorical', 'yahoo', 'yay', 'yazidi', 'yazidis', 'yea', 'yeah', 'year', 'yell', 'yellow', 'yemen', 'yes', 'yesterday', 'yet', 'yo', 'yobe', 'york', 'yorker', 'you', 'yougov', 'young', 'youngheroesid', 'your', 'yours', 'yourself', 'youth', 'youtube', 'ypres', 'yr', 'yugvani', 'yyc', 'z10', 'zayn', 'zero', 'zionism', 'zionist', 'zipper', 'zombie', 'zone', 'zouma', 'zss', 'åè', 'åê', 'åêdemolition', 'ûª', 'ûªd', 'ûªll', 'ûªre', 'ûªs', 'ûªt', 'ûªve', 'ûïa', 'ûïhannaph', 'ûïhatchet', 'ûïrichmond', 'ûïthe', 'ûïwe', 'ûïwhen', 'ûò', 'ûó']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2284, 4429)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use M = 2\n",
    "count_vect_real = CountVectorizer(binary=True, min_df=2)\n",
    "CountVec_train_real = count_vect_real.fit_transform(x_train).toarray()\n",
    "vnames = count_vect_real.get_feature_names()\n",
    "print(vnames)\n",
    "CountVec_valid_real = count_vect_real.transform(x_valid).toarray()\n",
    "CountVec_valid_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic regression. In this question, we will be training logistic regression models using bag of words feature vectors obtained in part (d). We will use the F 1-score as the evaluation metric.\n",
    "\n",
    "    We use F 1-score because it gives a more comprehensive view of classifier performance than\n",
    "    accuracy. For more information on this metric see F1-score.\n",
    "    We ask you to train the following classifiers. We suggest using the LogisticRegression implementation in sklearn.\n",
    "    \n",
    "    * Train a logistic regression model without regularization terms. You will notice that the default sklearn logistic regression utilizes L2 regularization. You can turn off L2 regu- larization by changing the penalty parameter. Report the F1 score in your training and in your development set. Comment on whether you observe any issues with overfitting or underfitting.\n",
    "    * Train a logistic regression model with L1 regularization. Sklearn provides some good examples for implementation. Report the performance on both the training and the development sets.\n",
    "    * Similarly, train a logistic regression model with L2 regularization. Report the perfor- mance on the training and the development sets.\n",
    "    * Which one of the three classifiers performed the best on your training and development set? Did you observe any overfitting and did regularization help reduce it? Support your answers with the classifier performance you got.\n",
    "    * Inspect the weight vector of the classifier with L1 regularization (in other words, look at the θ you got after training). You can access the weight vector of the trained model using the coef_ attribute of a LogisticRegression instance. What are the most important words for deciding whether a tweet is about a real disaster or not?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with logreg: 0.7079\n",
      "hurt\n",
      "outbreak\n",
      "mayhem\n",
      "plane\n",
      "source\n",
      "40\n",
      "myanmar\n",
      "hiroshima\n",
      "typhoon\n",
      "bombing\n"
     ]
    }
   ],
   "source": [
    "#logistics regression without regulation \n",
    "lr = LogisticRegression(penalty = 'none', C = 9999)\n",
    "lr.fit (CountVec_train_real, y_train)\n",
    "prediction_y = lr.predict(CountVec_valid_real)\n",
    "print('F1 score with logreg: %.4f' % f1_score(y_valid, prediction_y))\n",
    "weights = lr.coef_[0]\n",
    "sorted_weight_index = np.argsort(np.abs(lr.coef_[0])) #return the index of the sorted weights \n",
    "for i in sorted_weight_index[-10:]:\n",
    "    print(vnames[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with logreg: 0.7508\n",
      "california\n",
      "drought\n",
      "storm\n",
      "evacuate\n",
      "earthquake\n",
      "typhoon\n",
      "wildfire\n",
      "massacre\n",
      "bombing\n",
      "hiroshima\n"
     ]
    }
   ],
   "source": [
    "#logistics regression with regulation L2\n",
    "lr_l2 = LogisticRegression(penalty = 'l2')\n",
    "lr_l2.fit (CountVec_train_real, y_train)\n",
    "prediction_y = lr_l2.predict(CountVec_valid_real)\n",
    "print('F1 score with logreg: %.4f' % f1_score(y_valid, prediction_y))\n",
    "weights = lr_l2.coef_[0]\n",
    "sorted_weight_index = np.argsort(np.abs(lr_l2.coef_[0])) #return the index of the sorted weights \n",
    "for i in sorted_weight_index[-10:]:\n",
    "    print(vnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with logreg: 0.7412\n",
      "myanmar\n",
      "derailment\n",
      "massacre\n",
      "outbreak\n",
      "earthquake\n",
      "mh370\n",
      "migrant\n",
      "hiroshima\n",
      "bombing\n",
      "typhoon\n"
     ]
    }
   ],
   "source": [
    "#logistics regression with regulation L1\n",
    "lr_l1 = LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
    "lr_l1.fit (CountVec_train_real, y_train)\n",
    "prediction_y = lr_l1.predict(CountVec_valid_real)\n",
    "print('F1 score with logreg: %.4f' % f1_score(y_valid, prediction_y))\n",
    "weights = lr_l1.coef_[0]\n",
    "sorted_weight_index = np.argsort(np.abs(lr_l1.coef_[0])) #return the index of the sorted weights \n",
    "for i in sorted_weight_index[-10:]:\n",
    "    print(vnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation result for logistics regression without regulation is  {'fit_time': array([1.15430307, 0.98953795, 1.06057692, 1.00339603, 1.00738502]), 'score_time': array([0.02622986, 0.02428079, 0.02401519, 0.02459788, 0.02545309]), 'test_score': array([0.72795497, 0.74953096, 0.74765478, 0.73827392, 0.74084507]), 'train_score': array([0.98874032, 0.9859254 , 0.98522167, 0.98615998, 0.98827392])}\n",
      "The cross validation result for logistics regression with l2 regulation is  {'fit_time': array([0.68969083, 0.72944999, 0.72613811, 0.68315196, 0.67498088]), 'score_time': array([0.0267489 , 0.02406406, 0.02332592, 0.02389216, 0.02323103]), 'test_score': array([0.77016886, 0.7945591 , 0.79549719, 0.78705441, 0.78028169]), 'train_score': array([0.93760263, 0.93126906, 0.93361483, 0.93079991, 0.93269231])}\n",
      "The cross validation result for logistics regression with l1 regulation is  {'fit_time': array([0.30860209, 0.29218197, 0.29550123, 0.2941072 , 0.29299712]), 'score_time': array([0.02347088, 0.02052903, 0.02050567, 0.02032495, 0.02094793]), 'test_score': array([0.76547842, 0.77016886, 0.79643527, 0.79268293, 0.76056338]), 'train_score': array([0.87825475, 0.87684729, 0.87356322, 0.87192118, 0.87992495])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold\n",
    "\n",
    "#cross validation for logistics regression without regulation \n",
    "cv_dict = cross_validate(lr, CountVec_train_real, y_train, return_train_score=True)\n",
    "kfolds = KFold(n_splits = 10, random_state = 7)\n",
    "cv_dictKfold = cross_val_score(lr,CountVec_train_real,y_train,cv = kfolds, scoring ='accuracy')\n",
    "print('The cross validation result for logistics regression without regulation is ', cv_dict)\n",
    "#cross validation for logistics regression with l2 regulation\n",
    "cv_dict_l2 = cross_validate(lr_l2, CountVec_train_real, y_train, return_train_score=True)\n",
    "cv_dictKfold_l2 = cross_val_score(lr_l2,CountVec_train_real,y_train,cv = kfolds, scoring ='accuracy')\n",
    "\n",
    "print('The cross validation result for logistics regression with l2 regulation is ', cv_dict_l2)\n",
    "\n",
    "#cross validation for logistics regression with l1 regulation \n",
    "cv_dict_l1 = cross_validate(lr_l1, CountVec_train_real, y_train, return_train_score=True)\n",
    "cv_dictKfold_l1 = cross_val_score(lr_l1,CountVec_train_real,y_train,cv = kfolds, scoring ='accuracy')\n",
    "print('The cross validation result for logistics regression with l1 regulation is ', cv_dict_l1)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7350371707881336"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for accuracy using cross_val_score KFolds for model without regulation \n",
    "cv_dictKfold.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785668439391161"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for accuracy using cross_val_score KFolds for model with l1 regulation \n",
    "cv_dictKfold_l1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862612676155679"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for accuracy using cross_val_score KFolds for model with l2 regulation \n",
    "cv_dictKfold_l2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> \n",
    "By comparing the logistric regression with regulation, l1 regulation and l2 regulation using cross_validation methods, we can see that the model without regulation has a train score very close to 1, which is an indication of overfitting. Both l2 and l1 methods yield a normal train score, but l2 has a better accuracy than l1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bernoulli Naive Bayes.Implement a Bernoulli Naive Bayes classifier to predict the probability of whether each tweet is about a real disaster. Train this classifier on the training set, and report its F 1-score on the development set.\n",
    "    \n",
    "    Important: For this question you should implement the classifier yourself similar to what was shown in class, without using any existing machine learning libraries such as sklearn. You may only use basic libraries such as numpy.\n",
    "    \n",
    "    As you work on this problem, you may find that some words in the vocabulary occur in the development set but are not in the training set. As a result, the standard Naive Bayes model learns to assign them an occurrence probability of zero, which becomes problematic when we observe this \"zero probability\" event on our development set.\n",
    "    \n",
    "    The solution to this problem is a form of regularization called Laplace smoothing or additive smoothing. The idea is to use \"pseudo-counts\", i.e. to increment the number of times we have seen each word or document by some number of \"virtual\" occurrences α. Thus, the Naive Bayes model will behave as if every word or document has been seen at least α times.\n",
    "    \n",
    "    More formally, the ψjk parameter of Bernoulli Naive Bayes is the probability of observing word j within class k. Its normal maximum likelihood estimate is\n",
    "    \n",
    "    $$ \\frac{\\phi_k}{\\sum_l \\phi_l} = \\frac{n_jk}{n_k}$$\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "where nk is the number of documents of class k and n j k is the number of documents of class k that contain word j . In Laplace smoothing, we increment each counter n j k by α (thus we count each word an extra α times), and the resulting estimate for ψ j k becomes:\n",
    "\n",
    "$$ \\frac{\\phi_k}{\\sum_l \\phi_l} = \\frac{n_k + \\alpha}{n_k+2\\alpha}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56370801 0.43629199]\n"
     ]
    }
   ],
   "source": [
    "#Retrieve below code from course lecture slides#6\n",
    "n = CountVec_train_real.shape[0] # size of the dataset\n",
    "d = CountVec_train_real.shape[1] # number of features in our dataset\n",
    "K = 2 # number of clases\n",
    "\n",
    "# these are the shapes of the parameters\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])\n",
    "\n",
    "# we now compute the parameters\n",
    "for k in range(K):\n",
    "    vecTrain_k = CountVec_train_real[y_train == k]\n",
    "    psis[k] = np.mean(vecTrain_k, axis=0)\n",
    "    phis[k] = vecTrain_k.shape[0] / float(n)\n",
    "\n",
    "# print out the class proportions\n",
    "print(phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def nb_predictions(x, psis, phis):\n",
    "    #This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    #We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "\n",
    "    # adjust shapes\n",
    "    n, d = x.shape\n",
    "    x = np.reshape(x, (1, n, d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14)\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape([K,1])\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])\n",
    "\n",
    "idx, logpyx = nb_predictions(CountVec_train_real, psis, phis)\n",
    "idx_valid, logpyx_valid = nb_predictions(CountVec_valid_real, psis, phis)\n",
    "print(idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of predicted results on training data: 0.8882\n",
      "Mean of predicted results on valid data: 0.7916\n",
      "F1 score on the training set: 0.8645\n",
      "F1 score on the dev set: 0.7344\n"
     ]
    }
   ],
   "source": [
    "print('Mean of predicted results on training data: %.4f' % (idx==y_train).mean())\n",
    "print('Mean of predicted results on valid data: %.4f' % (idx_valid==y_valid).mean())\n",
    "print(\"F1 score on the training set: %.4f\" % f1_score(y_train, idx))\n",
    "print(\"F1 score on the dev set: %.4f\" % f1_score(y_valid, idx_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model comparison。 You just implemented a generative classifier and a discriminative classifier. Reflect on the following:\n",
    "    * Which model performed the best in predicting whether a tweet is of a real disaster or not? Include your performance metric in your response. Comment on the pros and cons of using generative vs discriminative models.\n",
    "    * Think about the assumptions that Naive Bayes makes. How are the assumptions differ- ent from logistic regressions? Discuss whether it’s valid and efficient to use Bernoulli Naive Bayes classifier for natural language texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> \n",
    "The bernouli naives bayes performes the best in predicting whether a teweet is of a real disaster as it has a F1_sore of 0.86 which is higher than all the logistics regression models (with or without regularization). The fundamental difference between discriminative models and generative models is that Discriminative models learn the (hard or soft) boundary between classes and Generative models model the distribution of individual classes. Naive Bayes (generative classifiers)  assume some functional form for $P(Y)$, $P(X|Y)$, estimate parameters of $P(X|Y)$, $P(Y)$ directly from training data, and use Bayes rule to calculate $P(Y|X)$. While Logistics regression (Discriminative Classifiers) assume some functional form for $P(Y|X)$ and estimates parameters of $P(Y|X)$ directly from training data. \n",
    "    \n",
    "The advantage of using generative classifiers is that we can assume the occurence of one word is not impacted by the occurence of the other word. So if the assumption is true, it will give us better accuracy. \n",
    "    \n",
    "The discriminative classifiers may not be very suitable in our natural language processing cases as some words will almost always appear together, which may violate the conditional independcy in this situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N-gram model.The N-gram model is similar to the bag of words model,but instead of using individual words we use N-grams, which are contiguous sequences of words. For example, using N = 2, we would says that the text “Alice fell down the rabbit hole” consists of the se- quence of 2-grams: [\"Alice fell\", \"fell down\", \"down the\", \"the rabbit\", \"rabbit hole\"], and the following sequence of 1-grams: [\"Alice\", \"fell\", \"down\", \"the\", \"rabbit\", \"hole\"]. All eleven of these symbols may be included in the vocabulary, and the feature vector x is defined according to xi = 1 if the i’th vocabulary symbol occurs in the tweet, and xi = 0 otherwise. Using N = 2, construct feature representations of the tweets in the training and development tweets. Again, you should choose a threshold M , and only include symbols in the vocabulary that occur in at least M different tweets in the training set. Discuss how you chose the thresh- old M, and report the total number of 1-grams and 2-grams in your vocabulary. In addition, take 10 2-grams from your vocabulary, and print them out.\n",
    "\n",
    "\n",
    "    Then, implement a logistic regression and a Bernoulli classifier to train on 2-grams. You may reuse the code in (e) and (f). You may also choose to use or not use a regularization term, depending on what you got from (e). Report your  results on training and development set. Do these results differ significantly from those using the bag of words model? Discuss what this implies about the task.\n",
    "    \n",
    "    Again, we suggest using CountVectorizer to construct these features. In order to include both 1-gram and 2-gram features, you can set ngram_range=(1,2). Note also that in this case, since there are probably many different 2-grams in the dataset, it is especially important carefully set min_df in order to avoid run-time and memory issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression + N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With M = 1, F1 score = 0.7486\n",
      "With M = 2, F1 score = 0.7450\n",
      "With M = 3, F1 score = 0.7451\n",
      "With M = 4, F1 score = 0.7347\n",
      "With M = 5, F1 score = 0.7374\n",
      "With M = 6, F1 score = 0.7388\n",
      "With M = 7, F1 score = 0.7349\n",
      "With M = 8, F1 score = 0.7358\n",
      "['0104', '010401', '010401 utc20150805', '02', '05', '06', '0day', '0day bug', '10', '100', '1000', '101', '101 to', '1030', '1030 pm', '1030pm', '10th', '11', '11yearold', '11yearold boy', '12', '1200', '12000', '12000 nigerian', '125', '13', '13 reason', '13000', '133', '14', '14 lez', '15', '15 km', '15 saudi', '150', '150401', '150401 1000', '16', '1620', '16yr', '16yr old', '17', '18', '18w', '18w cree', '18wheeler', '19', '19 km', '1980', '1980 prebreak', '1st', '20', '20 amp', '2005', '2010', '2011', '2013', '2013 the', '2014', '2015', '2015 australia', '2015 prebreak', '2030', '21', '22', '23', '24', '25', '25 home', '25 kill', '26', '27', '29', '2nd', '2pcs', '2pcs 18w', '30', '30 fire', '300', '300000', '300w', '300w curve', '31', '31 md', '32', '320', '320 ir', '33', '33 hollywood', '34', '35', '360wisenews', '360wisenews china', '361', '3d', '3rd', '40', '40 family', '4000', '4000 syrian', '45', '4wd', '4wd flood', '4x4', '4x4 offroad', '50', '500', '5000', '53', '53inch', '53inch 300w', '55', '60', '60 mph', '600', '64', '70', '70 year', '70 yr', '70th', '70th anniversary', '731', '731 japanese', '800', '852015', '86', '87', '90', '911', '95', '96', '97georgia', '97georgia ave', 'aba', 'aba woman', 'abandon', 'abandon aircraft', 'abbswinston', 'abbswinston zionist', 'abc', 'abc news', 'abcnew', 'abcnew obama', 'ability', 'ablaze', 'able', 'abortion', 'about', 'absolutely', 'abstorm', 'abuse', 'ac', 'access', 'accident', 'accident expert', 'accident man', 'accident property', 'accident the', 'accidentally', 'accionempresa', 'accord', 'accord the', 'account', 'accuse', 'acquire', 'acre', 'across', 'act', 'act mass', 'action', 'action hostage', 'action year', 'activate', 'activate municipal', 'active', 'active exploit', 'activity', 'actual', 'actually', 'acute', 'ad', 'add', 'add video', 'address', 'admit', 'admit arson', 'adult', 'advance', 'adventure', 'advisory', 'af', 'affect', 'affect the', 'afghan', 'afghanistan', 'afraid', 'africa', 'africa ap', 'after', 'after america', 'afternoon', 'aftershock', 'aftershock djicemoon', 'against', 'age', 'agency', 'agent', 'ago', 'ago today', 'agree', 'ah', 'ahead', 'aid', 'aim', 'aim taiwan', 'air', 'air accident', 'air ambulance', 'aircraft', 'aircraft debris', 'aircraft mma', 'airline', 'airline abc', 'airplane', 'airplane accident', 'airplane debris', 'airport', 'airport get', 'ak', 'aka', 'al', 'alabama', 'alabama home', 'alarm', 'alaska', 'alberta', 'album', 'alert', 'alex', 'alive', 'all', 'all meatloving', 'all the', 'allah', 'allege', 'allow', 'allow parole', 'ally', 'almost', 'alone', 'along', 'alp', 'alp kill', 'already', 'also', 'alternative', 'always', 'always get', 'am', 'amazing', 'amazon', 'ambulance', 'ambulance helicopter', 'ambulance sprinter', 'america', 'america be', 'america ûªs', 'american', 'american pipeline', 'americans', 'amid', 'amid crisis', 'among', 'amongst', 'amp', 'amp bush', 'amp he', 'amp service', 'amp tsunami', 'amp use', 'amsterdam', 'an', 'an airplane', 'an ambulance', 'an emergency', 'an oil', 'anchorage', 'anchorage alaska', 'ancient', 'ancient canaanite', 'ancient mayan', 'and', 'and linkury', 'and realise', 'and the', 'angel', 'angeles', 'anger', 'angry', 'angry odeon', 'animal', 'animal act', 'animal rescue', 'animalrescue', 'ankle', 'annihilate', 'annihilation', 'annihilation the', 'anniversary', 'anniversary hiroshima', 'anniversary the', 'announce', 'announcement', 'annual', 'another', 'another standus', 'another white', 'answer', 'anthrax', 'anthrax lab', 'anti', 'anti collision', 'antioch', 'any', 'anybody', 'anymore', 'anyone', 'anyone else', 'anything', 'anyway', 'aoms', 'aoms ibooklove', 'ap', 'ap ts', 'ap ûó', 'apartment', 'apc', 'apc pdp', 'apocalypse', 'apocalypse wither', 'apollo', 'apollo brown', 'apollobrown', 'app', 'app more', 'apparent', 'apparently', 'appear', 'appear be', 'apple', 'application', 'apply', 'apply to', 'appreciate', 'approach', 'apt', 'ar', 'arabia', 'area', 'arianagrande', 'arm', 'armageddon', 'armory', 'army', 'army beyhive', 'army directioner', 'army trench', 'around', 'arrest', 'arrest enugu', 'arrive', 'arrive sicily', 'arsenal', 'arson', 'arson scheme', 'arson suspect', 'arson victim', 'arsonist', 'arsonist arrest', 'art', 'article', 'as', 'asap', 'ash', 'ash 2015', 'ashe', 'asia', 'ask', 'asleep', 'ass', 'asshole', 'associate', 'at', 'at home', 'atomic', 'atomic bomb', 'atomic bombing', 'atomic level', 'attack', 'attack gun', 'attack kill', 'attack militant', 'attack muslim', 'attack police', 'attack the', 'attempt', 'attend', 'attention', 'auction', 'audience', 'audio', 'aug', 'aug 06', 'aug 2015', 'august', 'august 05', 'aussie', 'australia', 'australia ûªs', 'australian', 'auth', 'author', 'authority', 'automatic', 'automatic frontline', 'av', 'avalanche', 'ave', 'ave silver', 'avenue', 'average', 'avert', 'avert police', 'avoid', 'avoid microlight', 'await', 'aware', 'away', 'awesome', 'awful', 'b4', 'baby', 'baby without', 'back', 'back school', 'back the', 'background', 'bad', 'badge', 'bag', 'bag meek', 'bag white', 'bag women', 'ball', 'ban', 'ban be', 'ban quarantine', 'ban quarantined', 'band', 'bang', 'bang nearby', 'bank', 'bar', 'bar 4x4', 'bar admit', 'barackobama', 'bargain', 'base', 'baseball', 'bash', 'bat', 'bath', 'bathroom', 'batter', 'battery', 'battle', 'battle occur', 'battle the', 'battlefield', 'bay', 'bay area', 'bayelsa', 'bayelsa patience', 'bayelsa poll', 'bb17', 'bb4sp', 'bbc', 'bbc cnn', 'bbc news', 'bc', 'be', 'be able', 'be after', 'be big', 'be blast', 'be bomb', 'be bring', 'be charge', 'be confirm', 'be costlier', 'be dead', 'be deluge', 'be do', 'be electrocute', 'be engulf', 'be finally', 'be fire', 'be first', 'be go', 'be great', 'be hour', 'be in', 'be inundate', 'be kill', 'be look', 'be loud', 'be move', 'be not', 'be ok', 'be one', 'be pandemonium', 'be people', 'be plague', 'be prosecute', 'be scream', 'be sink', 'be suppose', 'be the', 'be true', 'be two', 'be whole', 'beach', 'beam', 'beam full', 'bear', 'beat', 'beautiful', 'because', 'become', 'bed', 'bedroom', 'bee', 'been', 'beer', 'before', 'beforeitsnew', 'begin', 'begin examine', 'behind', 'belief', 'believe', 'believe be', 'believe the', 'believe what', 'bell', 'belong', 'ben', 'benefit', 'besides', 'bestnaijamade', 'bestnaijamade 16yr', 'bestnaijamade be', 'bestnaijamade bestnaijamade', 'bet', 'beyhive', 'beyonce', 'beyonce my', 'beyond', 'bicycle', 'bicyclist', 'bicyclist injure', 'bid', 'big', 'big project', 'bill', 'bin', 'bin laden', 'bind', 'biological', 'bioterror', 'bioterror germ', 'bioterror pathogen', 'bioterrorism', 'bioterrorism sir', 'bird', 'birthday', 'bit', 'bitch', 'bite', 'bjp', 'black', 'black eye', 'black hat', 'blackberry', 'blackberry z10', 'blame', 'blast', 'blast lack', 'blast near', 'blast wind', 'blaze', 'blaze hot', 'bleed', 'bless', 'blessing', 'blight', 'blizzard', 'blk', 'block', 'block mod', 'block the', 'blog', 'blood', 'bloody', 'bloody hell', 'blow', 'blow in', 'blow the', 'blowout', 'blue', 'bluejay', 'blvd', 'board', 'boat', 'boat capsize', 'boat carry', 'boat mining', 'boat sink', 'bob', 'bob apocalypse', 'body', 'body bag', 'body water', 'bolster', 'bomb', 'bomb ass', 'bomb bestnaijamade', 'bomb japan', 'bomb saudi', 'bomb the', 'bomb turkey', 'bomber', 'bomber attack', 'bomber detonate', 'bomber kill', 'bombing', 'bombing egg', 'bombing hiroshima', 'bombing still', 'book', 'bookboost', 'boom', 'boot', 'boss', 'boston', 'both', 'bottom', 'boundary', 'bout', 'bowl', 'bowling', 'box', 'boxer', 'boy', 'boy be', 'boy charge', 'boyfriend', 'brain', 'brake', 'brand', 'brave', 'brazil', 'break', 'break news', 'breakingnew', 'brick', 'bridge', 'bridge collapse', 'bring', 'bring back', 'bring climate', 'bring tornado', 'britain', 'british', 'bro', 'bro party', 'broad', 'broadway', 'brooklyn', 'brooklyn sinkhole', 'brother', 'brown', 'brown detonate', 'browser', 'browser hijacker', 'bruh', 'brutally', 'bs', 'btwn', 'budget', 'buffalo', 'bug', 'bug fully', 'build', 'building', 'building burn', 'building fire', 'building on', 'bullet', 'bulletin', 'bully', 'bundle', 'burn', 'burn building', 'burn like', 'burn man', 'burn the', 'burning', 'burst', 'bus', 'bus 361', 'bus arrest', 'bus hijacker', 'bush', 'bush fire', 'business', 'business deluge', 'but', 'butt', 'butter', 'button', 'buy', 'by', 'by give', 'by sandstorm', 'bypass', 'c130', 'c130 specially', 'cabin', 'cable', 'cable tv', 'cake', 'calamity', 'calgary', 'calgary activate', 'calif', 'california', 'california fire', 'california school', 'california spring', 'california time20150805', 'california time20150806', 'california wild', 'california wildfire', 'call', 'call ban', 'call duty', 'calm', 'cameroon', 'camp', 'campaign', 'campus', 'can', 'can be', 'can keep', 'can not', 'can see', 'can ûªt', 'canaanite', 'canada', 'cancel', 'cancer', 'canyon', 'canyon crew', 'capital', 'capsize', 'capsize libya', 'captain', 'capture', 'capture violent', 'car', 'car accident', 'car engulf', 'car truck', 'car wreck', 'card', 'care', 'career', 'careful', 'cargo', 'carry', 'case', 'casualty', 'casualty call', 'cat', 'catastrophe', 'catastrophic', 'catastrophic effect', 'catastrophic eruption', 'catastrophic structural', 'catch', 'catch fire', 'catch northern', 'cause', 'cause damage', 'cause fatal', 'cause metro', 'cause structural', 'caution', 'cave', 'cdc', 'cdt', 'cdt august', 'cdt nws', 'cecilthelion', 'center', 'central', 'centre', 'centre film', 'ceo', 'ceo steve', 'certain', 'certainly', 'certificate', 'chain', 'chair', 'challenge', 'chance', 'change', 'change god', 'change windstorm', 'channel', 'chaos', 'character', 'charge', 'charge fatal', 'charge manslaughter', 'charger', 'charity', 'charlie', 'chart', 'chase', 'check', 'check out', 'check this', 'cheese', 'chelsea', 'chemical', 'chemical company', 'chemical dependency', 'chemical explosion', 'chemical spill', 'chicago', 'chicagoarea', 'chicagoarea gay', 'chief', 'chief diamondkesawn', 'child', 'chile', 'chile 33', 'chill', 'china', 'china stock', 'china ûªs', 'chinese', 'chocolate', 'choice', 'choice 14', 'choke', 'choke hazard', 'choose', 'chris', 'christian', 'christian attack', 'christmas', 'christmas tree', 'church', 'cia', 'cigarette', 'cinema', 'cinema evacuate', 'city', 'city calgary', 'city girl', 'civil', 'civilian', 'civilian casualty', 'claim', 'claim responsibility', 'claim suicide', 'class', 'clean', 'cleanup', 'clear', 'clearedincident', 'clearedincident injuryi495', 'clearly', 'cleveland', 'click', 'client', 'cliff', 'climate', 'climate change', 'climb', 'clinton', 'clip', 'close', 'closure', 'clothe', 'cloud', 'club', 'clutch', 'cnn', 'cnn islam', 'co', 'coach', 'coach my', 'coast', 'coast tram', 'coastal', 'coastal german', 'coat', 'cock', 'coffee', 'cofounder', 'cofounder ceo', 'cold', 'collapse', 'collapse nearby', 'collapse story', 'collapse tell', 'collapse the', 'collapse trent', 'collection', 'collide', 'collide the', 'collision', 'collision broadway', 'collision rear', 'collisionno', 'collisionno inj', 'color', 'colorado', 'colorado theater', 'colour', 'colour shape', 'combat', 'combat magnum', 'combo', 'combo 53inch', 'come', 'come active', 'come an', 'come back', 'come home', 'come land', 'come of', 'come soon', 'come the', 'come with', 'comment', 'comment rule', 'commercial', 'commit', 'commit mass', 'common', 'community', 'company', 'comparison', 'complete', 'completely', 'compliant', 'compliant ebay', 'computer', 'computer send', 'concern', 'concert', 'conclusively', 'conclusively confirm', 'condemn', 'condition', 'condition genocide', 'conference', 'confirm', 'confirm from', 'confirm mh370', 'confirm rì', 'conflict', 'congress', 'connector', 'consequence', 'consider', 'constant', 'constantly', 'contact', 'contain', 'content', 'content policy', 'content reddit', 'continue', 'continue severe', 'control', 'cook', 'cook you', 'cool', 'cop', 'cope', 'copilot', 'copycat', 'copycat massacre', 'cord', 'corner', 'correction', 'correction tent', 'cos', 'cost', 'costlier', 'costlier big', 'cotton', 'could', 'could not', 'could reduce', 'counselor', 'counselor intern', 'country', 'country hunk', 'county', 'county georgia', 'couple', 'couple spend', 'course', 'course course', 'court', 'cousin', 'cover', 'coworker', 'cr', 'crack', 'crackdown', 'cramer', 'crane', 'crane hold', 'crap', 'crash', 'crash avoid', 'crash burn', 'crash cause', 'crash course', 'crash last', 'crash near', 'crash site', 'crash summer', 'crash there', 'crater', 'crazy', 'cream', 'create', 'create the', 'credit', 'cree', 'cree lead', 'crematoria', 'crematoria provoke', 'crew', 'crew advance', 'crew evacuate', 'crew investigate', 'cricket', 'crime', 'criminal', 'criminal hijack', 'crisis', 'crisis famine', 'cross', 'cross body', 'crowd', 'crush', 'cruz', 'cry', 'crystal', 'cuff', 'cum', 'cunt', 'cup', 'cupcake', 'curb', 'curfew', 'current', 'currently', 'curve', 'curve cree', 'custom', 'cut', 'cute', 'cuz', 'cyclist', 'cyclone', 'cyclone warning', 'da', 'dad', 'daily', 'damage', 'damage plug', 'damn', 'dan', 'dance', 'dance ices', 'danger', 'danger come', 'dangerous', 'daniel', 'dare', 'dark', 'darude', 'darude sandstorm', 'date', 'date charity', 'datum', 'datum sound', 'daughter', 'david', 'davidvonderhaar', 'day', 'day feed', 'day without', 'dc', 'de', 'dead', 'dead aim', 'dead dozen', 'dead exchange', 'deadly', 'deadly outbreak', 'deal', 'dear', 'death', 'death america', 'death toll', 'debate', 'debris', 'debris confirm', 'debris find', 'debris from', 'debt', 'decide', 'decision', 'deck', 'declaration', 'declaration northern', 'declare', 'declare disaster', 'deep', 'defense', 'define', 'definitely', 'degree', 'delay', 'deliver', 'deliver baby', 'deluge', 'deluge invoice', 'dem', 'demand', 'demand ûïhatchet', 'democracy', 'demolish', 'demolish house', 'demolish spring', 'demolition', 'demolition derby', 'demon', 'denver', 'denver collision', 'deny', 'department', 'dependency', 'dependency counselor', 'depth', 'deputy', 'derail', 'derail downtown', 'derail madhya', 'derail smithsonian', 'derail two', 'derail ur', 'derailment', 'derailment freakiest', 'derailment village', 'derby', 'describe', 'description', 'desert', 'deserve', 'design', 'desire', 'desire be', 'desolate', 'desolation', 'desolation smaug', 'destiny', 'destiny block', 'destroy', 'destroy food', 'destroy home', 'destruction', 'detail', 'detain', 'detectado', 'detectado japìn', 'detonate', 'detonate bomb', 'detonate mop', 'detonate you', 'detonation', 'detonation sensor', 'detonation sensorsenso', 'devastate', 'devastated', 'devastation', 'devastation wrought', 'develop', 'device', 'di', 'di maria', 'diamondkesawn', 'diamondkesawn release', 'dick', 'die', 'die human', 'die the', 'die wing', 'diet', 'different', 'dinner', 'direction', 'direction my', 'directioner', 'director', 'disappear', 'disappoint', 'disaster', 'disaster avert', 'disaster declaration', 'disaster typhoondevastate', 'disco', 'discover', 'discovery', 'discovery crash', 'discuss', 'disea', 'disease', 'disease edinburgh', 'disease what', 'disney', 'displace', 'displace people', 'displace rohingya', 'disrupt', 'diss', 'distance', 'diving', 'djicemoon', 'djicemoon dubstep', 'dk', 'dk eyewitness', 'dnb', 'dnb edm', 'do', 'do anything', 'do get', 'do god', 'do not', 'do prefer', 'do shit', 'do stop', 'dock', 'doctor', 'document', 'dog', 'dollar', 'dolphin', 'domestic', 'don', 'don ûªt', 'door', 'dorret', 'double', 'doubt', 'down', 'download', 'download earthquake', 'download video', 'downtown', 'downtown dc', 'downtown emergency', 'dozen', 'dozen injure', 'dr', 'dragon', 'drake', 'drake body', 'dramatic', 'dream', 'dress', 'dress meme', 'drift', 'drill', 'drink', 'drinking', 'drive', 'driver', 'droid', 'drone', 'drop', 'drought', 'drown', 'drown in', 'drown migrant', 'drown my', 'drown the', 'drowning', 'drug', 'drum', 'drunk', 'drunk meal', 'dry', 'dtn', 'dublin', 'dubstep', 'dubstep trapmusic', 'dude', 'dude bro', 'due', 'dust', 'dust amp', 'dust storm', 'duty', 'dvd', 'each', 'ear', 'early', 'early week', 'earn', 'earth', 'earthquake', 'earthquake app', 'earthquake km', 'earthquake occur', 'east', 'easy', 'eat', 'eb', 'ebay', 'ebay auction', 'ebola', 'ebola case', 'economic', 'economy', 'eden', 'eden hazard', 'edinburgh', 'edinburgh to', 'edition', 'editor', 'editor chief', 'edm', 'edm dance', 'edt', 'education', 'effect', 'effect hiroshima', 'effect many', 'effort', 'egg', 'egg bus', 'ego', 'egypt', 'eight', 'either', 'el', 'election', 'electric', 'electrical', 'electrocute', 'electronic', 'elephant', 'elevate', 'else', 'em', 'email', 'emerge', 'emergency', 'emergency crew', 'emergency department', 'emergency plan', 'emergency preparedness', 'emergency response', 'emergency service', 'emergency unit', 'emmerdale', 'emmerdale summerfate', 'emotion', 'emotional', 'emotional wreck', 'end', 'end the', 'enemy', 'enemy derail', 'energy', 'engine', 'england', 'english', 'engulf', 'engulf flame', 'engulf tribal', 'engulfed', 'enjoy', 'enough', 'enter', 'entertainment', 'entire', 'entire pond', 'enugu', 'enugu photo', 'ep', 'epic', 'epicentre', 'episode', 'eq', 'equipment', 'er', 'error', 'eruption', 'escape', 'escape car', 'especially', 'estate', 'estimate', 'estimate grow', 'etc', 'eu', 'europe', 'evacuate', 'evacuate follow', 'evacuation', 'evacuation abandon', 'evacuation order', 'even', 'even it', 'evening', 'event', 'ever', 'ever since', 'every', 'every time', 'every year', 'everyday', 'everyone', 'everything', 'everywhere', 'evidence', 'evil', 'ex', 'exactly', 'examine', 'examine airplane', 'example', 'excellent', 'except', 'exchange', 'exchange gunfire', 'exchange shot', 'excuse', 'executive', 'executive be', 'exist', 'exit', 'exit 31', 'exp', 'expand', 'expect', 'experience', 'experiment', 'experiment unit', 'expert', 'expert france', 'explode', 'explode the', 'exploit', 'exploration', 'explosion', 'explosion nu', 'explosionproof', 'explosionproof temper', 'expose', 'express', 'extend', 'external', 'extreme', 'extremely', 'extremely offensive', 'eye', 'eye space', 'eyewitness', 'eyewitness account', 'eyewitness news', 'eyewitness travel', 'faan', 'faan order', 'face', 'face photo', 'facebook', 'facility', 'fact', 'factory', 'fail', 'failure', 'failure result', 'failure the', 'fair', 'fake', 'falcon', 'fall', 'fall cliff', 'false', 'false fire', 'fam', 'family', 'family affect', 'family plane', 'family sue', 'family those', 'famine', 'famine memorie', 'famine memory', 'famous', 'fan', 'fan angry', 'fan army', 'fantastic', 'fantasy', 'far', 'far runway', 'far the', 'faroeisland', 'farrakhan', 'farrakhan quote', 'fashion', 'fashion model', 'fast', 'fat', 'fatal', 'fatal crash', 'fatal outbreak', 'fatal sh', 'fatal virgin', 'fatal waimate', 'fatality', 'fate', 'father', 'faux', 'faux leather', 'favorite', 'favorite amp', 'favourite', 'fbi', 'fear', 'fear copycat', 'fear drown', 'fear kill', 'fear miss', 'feast', 'feat', 'feat mop', 'federal', 'fedex', 'fedex long', 'fedex stop', 'feed', 'feed 4000', 'feel', 'feel attack', 'feel like', 'feel today', 'feel you', 'feeling', 'female', 'feminist', 'feminist the', 'ferguson', 'festival', 'fettilootch', 'fettilootch slanglucci', 'few', 'field', 'fight', 'fight bioterrorism', 'fight blight', 'figure', 'file', 'fill', 'film', 'film blackberry', 'film fan', 'final', 'finally', 'finally demolish', 'finally panic', 'financial', 'find', 'find la', 'find reunion', 'fine', 'finger', 'finger cross', 'finish', 'finnish', 'fire', 'fire alarm', 'fire be', 'fire burn', 'fire catch', 'fire crew', 'fire kill', 'fire please', 'fire rage', 'fire the', 'fire truck', 'firefighter', 'first', 'first hijacking', 'first lady', 'first responder', 'first time', 'fish', 'fish tank', 'fit', 'fitness', 'five', 'five year', 'fix', 'flag', 'flag via', 'flame', 'flame parleys', 'flash', 'flash flood', 'flat', 'flatten', 'fleet', 'fleet total', 'flight', 'flight mh370', 'flip', 'float', 'flood', 'flood be', 'flood beam', 'flood combo', 'flood derail', 'flood ur', 'flooding', 'flooding kill', 'floor', 'florida', 'fly', 'focus', 'focus cause', 'fog', 'fog lamp', 'follow', 'follow false', 'follow go', 'follower', 'food', 'food crematoria', 'foot', 'footage', 'football', 'for', 'for catastrophe', 'force', 'forecast', 'forest', 'forest fire', 'forest service', 'forest stop', 'forever', 'forget', 'forgive', 'forgot', 'form', 'former', 'former executive', 'former first', 'former township', 'fort', 'forward', 'foster', 'foul', 'four', 'fox', 'foxnew', 'fr', 'france', 'france begin', 'freak', 'freak accident', 'freakiest', 'freakiest freak', 'free', 'freedom', 'freeze', 'french', 'french air', 'friday', 'friend', 'frog', 'from', 'from flight', 'from hellfire', 'from mh370', 'from miss', 'front', 'frontline', 'frontline vehicle', 'fruit', 'ft', 'ft mop', 'fuck', 'fucking', 'fuel', 'fukushima', 'fukushima nuclear', 'full', 'full re', 'full rea', 'full read', 'fully', 'fully patch', 'fun', 'fund', 'funny', 'funny moment', 'funtenna', 'funtenna hijacking', 'future', 'fwy', 'fyi', 'gadget', 'gain', 'galactic', 'galactic crash', 'galactic spaceship', 'game', 'gamergate', 'gang', 'garden', 'gas', 'gay', 'gay bar', 'gaza', 'gaza blast', 'gbbo', 'gear', 'geller', 'gem', 'gem the', 'general', 'generally', 'generation', 'genocide', 'genocide ihhen', 'genocide refugee', 'george', 'georgia', 'gerenciatodo', 'germ', 'germ wake', 'german', 'german shepherd', 'germany', 'get', 'get back', 'get blow', 'get demolish', 'get home', 'get of', 'get swallow', 'get the', 'get to', 'get trouble', 'get work', 'gets', 'getting', 'giant', 'giant crane', 'gift', 'girl', 'girl country', 'girlfriend', 'give', 'give half', 'glad', 'glass', 'glass screen', 'global', 'global warming', 'gm', 'gm pray', 'go', 'go ahead', 'go and', 'go back', 'go be', 'go do', 'go effect', 'go get', 'go in', 'go the', 'go to', 'goat', 'god', 'god be', 'god isis', 'god order', 'going', 'gold', 'gold coast', 'golf', 'gon', 'good', 'good thing', 'good way', 'good you', 'google', 'gop', 'got', 'gov', 'government', 'governor', 'governor allow', 'govt', 'grab', 'grabber', 'grabber demand', 'grace', 'grateful', 'graze', 'great', 'great danger', 'greece', 'green', 'green line', 'grenade', 'grief', 'grief ûª', 'grill', 'grill arrive', 'ground', 'group', 'grow', 'gt', 'gta', 'gtgt', 'gtgtgt', 'guard', 'guardian', 'guess', 'guide', 'gun', 'gun grabber', 'gunfire', 'gunman', 'gunman hoax', 'gust', 'guy', 'habit', 'hack', 'haha', 'hail', 'hailstorm', 'hair', 'half', 'half date', 'hamas', 'hamas terrorist', 'hand', 'handbag', 'handbag cross', 'handbag faux', 'hang', 'happen', 'happen we', 'happiness', 'happy', 'happy birthday', 'harbor', 'hard', 'harm', 'harm good', 'hat', 'hat 2015', 'hate', 'have', 'have detonate', 'have evacuate', 'have meltdown', 'have not', 'have try', 'hawaii', 'hawaii time20150806', 'hazard', 'hazardous', 'hazardous weather', 'hazardous your', 'hd', 'he', 'he do', 'he flood', 'he still', 'head', 'head the', 'headline', 'heal', 'health', 'health amp', 'health care', 'hear', 'hear loud', 'hearing', 'heart', 'heart attack', 'heart sink', 'heartless', 'heartless owner', 'heat', 'heat since', 'heat wave', 'heaven', 'heavy', 'heavy rain', 'helicopter', 'helicopter crash', 'hell', 'hellfire', 'hellfire even', 'hello', 'help', 'help hand', 'help the', 'her', 'here', 'here ûªs', 'hero', 'hey', 'hi', 'hieroglyphic', 'hieroglyphic honor', 'high', 'high school', 'highway', 'hijack', 'hijack apc', 'hijack lorry', 'hijacker', 'hijacking', 'hijacking computer', 'hilarious', 'hill', 'hip', 'hip hop', 'hire', 'hiroshima', 'hiroshima 70', 'hiroshima atomic', 'hiroshima bombing', 'hiroshima nagasaki', 'his', 'history', 'hit', 'hit the', 'hoax', 'hoax device', 'hobbit', 'hobbit desolation', 'hobo', 'hobo purse', 'hoe', 'hold', 'hold bridge', 'hold hostage', 'holiday', 'holland', 'hollywood', 'hollywood movie', 'holy', 'home', 'home crew', 'home danger', 'home quarantine', 'home raze', 'home your', 'homeless', 'honestly', 'honey', 'honor', 'honor lowly', 'hop', 'hope', 'hope be', 'hope discovery', 'hope everyone', 'hope fall', 'hopefully', 'horrible', 'horrible accident', 'horrible sinking', 'horrible subreddit', 'horror', 'horror etc', 'horror ûïwhen', 'horse', 'horse it', 'horse via', 'hospital', 'host', 'hostage', 'hostage iran', 'hostage libya', 'hot', 'hot c130', 'hot funtenna', 'hot reddit', 'hotel', 'hour', 'hour away', 'house', 'house level', 'housing', 'houston', 'how', 'huffman', 'huffman unveil', 'huge', 'huh', 'human', 'human experiment', 'human history', 'humanity', 'hundred', 'hundred fear', 'hundred migrant', 'hunger', 'hungry', 'hunk', 'hunk strand', 'hunt', 'hunter', 'hurricane', 'hurt', 'hwo', 'hwy', 'hybrid', 'i77', 'ian', 'ianhellfire', 'ibooklove', 'ibooklove bookboost', 'ice', 'ice cream', 'icemoon', 'icemoon aftershock', 'ices', 'idea', 'idfire', 'idk', 'idp', 'idp internally', 'ie', 'ie madinah', 'if', 'if be', 'if have', 'if want', 'ig', 'ignition', 'ignition knock', 'ignore', 'ihhen', 'ihhen msf', 'ii', 'iii', 'ill', 'illegal', 'image', 'imagine', 'impact', 'impossible', 'in', 'in flame', 'in the', 'incident', 'include', 'increase', 'incredible', 'indeed', 'independent', 'india', 'india terrorism', 'indian', 'indian express', 'individual', 'indonesia', 'industry', 'info', 'information', 'inj', 'injure', 'injure denver', 'injure gaza', 'injure suspect', 'injury', 'injury happen', 'injury the', 'injuryi495', 'injuryi495 inner', 'ink', 'inner', 'inner loop', 'inning', 'innocent', 'insane', 'inside', 'instagram', 'instead', 'instruction', 'insurance', 'insurer', 'intensity', 'interest', 'interested', 'interesting', 'intern', 'internally', 'internally displace', 'international', 'internet', 'intersection', 'interview', 'into', 'into land', 'inundate', 'inundation', 'invalid', 'invasion', 'invest', 'investigate', 'investigate cause', 'investigation', 'investigator', 'investigator rule', 'investigator say', 'investigator shift', 'investigator the', 'invoice', 'invoice make', 'involve', 'involve fleet', 'iphone', 'iphone user', 'ir', 'ir icemoon', 'iran', 'iran 1980', 'irandeal', 'iranian', 'iraq', 'irish', 'isis', 'isis claim', 'isis terrorism', 'islam', 'islam truth', 'islamic', 'islamic state', 'island', 'island french', 'island from', 'island it', 'israel', 'israeli', 'israeli flag', 'issue', 'issue august', 'issue hazardous', 'issue ramag', 'issue severe', 'it', 'it be', 'it by', 'it collapse', 'it ll', 'it look', 'it make', 'it possible', 'it so', 'it take', 'it will', 'it ûªs', 'italian', 'italian alp', 'italy', 'its', 'its likely', 'its still', 'itune', 'jack', 'jackson', 'jacksonville', 'jail', 'jam', 'jamaica', 'jan', 'japan', 'japan mark', 'japan still', 'japanese', 'japanese military', 'japìn', 'jax', 'jay', 'jean', 'jeb', 'jesus', 'jet', 'jewish', 'job', 'job job', 'joe', 'john', 'join', 'join we', 'joint', 'joke', 'jon', 'jonathan', 'jonathan plan', 'journalist', 'joy', 'jst', 'july', 'just', 'just hear', 'just saddlebrooke', 'just want', 'justice', 'justify', 'justinbieber', 'kaduna', 'karachi', 'keep', 'keep animal', 'keep eye', 'kenya', 'kerricktrial', 'key', 'kick', 'kid', 'kid get', 'kidnap', 'kill', 'kill 15', 'kill cause', 'kill exchange', 'kill gunman', 'kill kurdish', 'kill least', 'kill pakistani', 'kill severe', 'kill three', 'killer', 'killer queen', 'killing', 'kind', 'kinda', 'kindle', 'king', 'kingdom', 'kiss', 'kit', 'km', 'km anchorage', 'km of', 'knee', 'knock', 'knock detonation', 'know', 'know be', 'know the', 'know to', 'know you', 'koin6news', 'kurdish', 'kurdish militant', 'kurtschlichter', 'la', 'la reunion', 'lab', 'lab mishap', 'lack', 'lack action', 'laden', 'laden family', 'lady', 'lady shoulder', 'lake', 'lamp', 'lamp car', 'lamp full', 'land', 'land be', 'land peace', 'land stadium', 'landing', 'landscape', 'landslide', 'landslide italian', 'lane', 'language', 'large', 'large sinkhole', 'last', 'last night', 'last week', 'last year', 'late', 'late home', 'late travel', 'later', 'laugh', 'launch', 'lava', 'lava blast', 'lava cake', 'law', 'lay', 'lead', 'lead work', 'leader', 'leadership', 'league', 'leak', 'learn', 'learn the', 'least', 'leather', 'leather hobo', 'leave', 'leg', 'legacy', 'legacy catastrophic', 'legal', 'legion', 'legionnaire', 'legionnaire disea', 'legionnaire disease', 'legionnaire than', 'lego', 'leo', 'less', 'lesson', 'let', 'let get', 'let go', 'let ûªs', 'lethal', 'level', 'level summer', 'lez', 'lez compliant', 'lgbt', 'library', 'library prepare', 'libya', 'libya india', 'lie', 'life', 'life wheavenly', 'lift', 'light', 'light bar', 'light offroad', 'lighten', 'lighting', 'lightning', 'lightning reshape', 'lightning strike', 'like', 'like be', 'like burn', 'like condition', 'like full', 'like mudslide', 'like the', 'like tornado', 'like tsunami', 'like war', 'like would', 'like you', 'like youtube', 'likely', 'likely rise', 'lil', 'limited', 'line', 'link', 'link 30', 'link reddit', 'linkury', 'linkury browser', 'lion', 'lip', 'list', 'listen', 'listenlive', 'literally', 'little', 'live', 'live late', 'live recount', 'live the', 'll', 'lmao', 'lmfao', 'load', 'loan', 'local', 'localarsonist', 'location', 'lock', 'logo', 'lol', 'london', 'london engulf', 'lone', 'lonewolffur', 'long', 'long ship', 'long transport', 'look', 'look like', 'look my', 'look state', 'look the', 'look you', 'loop', 'loop exit', 'loose', 'loot', 'lord', 'lord amp', 'lorry', 'lorry bus', 'los', 'los angeles', 'lose', 'loss', 'lot', 'loud', 'loud bang', 'louis', 'louis vuitton', 'love', 'love woman', 'lovely', 'lovely dust', 'low', 'low selfimage', 'lowly', 'lowly king', 'lownde', 'lownde county', 'lt', 'lt3', 'luck', 'lucky', 'lucky block', 'lulgzimbestpict', 'lunch', 'lung', 'm194', 'mac', 'machine', 'mad', 'mad max', 'madhya', 'madhya pradesh', 'madinah', 'madinah prophetmuhammad', 'madison', 'magic', 'magnum', 'magnum opus', 'mail', 'main', 'maintenance', 'major', 'majority', 'make', 'make look', 'make stand', 'make way', 'malaysia', 'malaysia airline', 'malaysia confirm', 'malaysia pm', 'malaysian', 'malaysian official', 'mama', 'man', 'man charge', 'man die', 'man escape', 'management', 'manager', 'manchester', 'mansehra', 'mansion', 'mansion fire', 'manslaughter', 'manslaughter the', 'manslaughter toddler', 'many', 'many horrible', 'many life', 'map', 'maria', 'marians', 'marine', 'mark', 'mark 70', 'mark 70th', 'marker', 'market', 'market crash', 'marvel', 'mary', 'maryland', 'maryland mansion', 'mass', 'mass murder', 'mass murderer', 'massacre', 'massacre antioch', 'massive', 'master', 'match', 'material', 'matter', 'max', 'max screenshot', 'maximum', 'may', 'may be', 'may cause', 'mayan', 'mayan tablet', 'maybe', 'mayhem', 'md', 'md 97georgia', 'meal', 'meal 101', 'mean', 'meat', 'meatloving', 'meatloving feminist', 'med', 'med migrant', 'med rescuer', 'medical', 'mediterran', 'mediterranean', 'medium', 'meek', 'meet', 'meeting', 'melt', 'meltdown', 'member', 'meme', 'meme officially', 'memorial', 'memorie', 'memory', 'memphis', 'mention', 'mercy', 'mess', 'message', 'messenger', 'messenger bag', 'met', 'metal', 'method', 'metric', 'metro', 'metro train', 'mexico', 'mh370', 'mh370 aircraft', 'mh370 be', 'mh370 malaysia', 'mh370 relative', 'mhtw4fnet', 'michael', 'michigan', 'microlight', 'microsoft', 'middle', 'middle east', 'might', 'migrant', 'migrant arrive', 'migrant boat', 'migrant med', 'migrant the', 'mike', 'mikeparractor', 'mile', 'militant', 'militant attack', 'militant suicide', 'militant tonight', 'military', 'military lulgzimbestpict', 'milkshake', 'mill', 'million', 'min', 'mind', 'mine', 'minecraft', 'minecraft night', 'miner', 'miner release', 'miner star', 'mini', 'mining', 'mining 4wd', 'minion', 'minister', 'minority', 'minority woman', 'minute', 'mishap', 'miss', 'miss malaysia', 'miss mh370', 'miss migrant', 'mission', 'mistake', 'mix', 'mlb', 'mma', 'mo', 'mod', 'mod bob', 'mode', 'model', 'model mayhem', 'modi', 'modify', 'modify land', 'mom', 'moment', 'money', 'monkey', 'monogram', 'monster', 'month', 'mood', 'moon', 'mop', 'mop detonate', 'more', 'more harm', 'more information', 'morning', 'mosque', 'mosque reuter', 'mosque suicide', 'most', 'moth', 'mother', 'motor', 'motorcycle', 'motorcyclist', 'motorcyclist bicyclist', 'mount', 'mount wave', 'mountain', 'mountain snowstorm', 'mourning', 'mourning notice', 'move', 'move the', 'movement', 'movie', 'movie theatre', 'movie trap', 'mp', 'mp live', 'mph', 'mph hail', 'mph wind', 'mr', 'ms', 'msf', 'msf refugee', 'mt', 'mtvhottest', 'much', 'mud', 'mudslide', 'mudslide cake', 'multiplayer', 'mum', 'mumbai', 'municipal', 'municipal emergency', 'murder', 'murder hamas', 'murderer', 'murderous', 'murderous story', 'muscle', 'museum', 'music', 'music video', 'musician', 'muslim', 'muslim the', 'must', 'my', 'my favorite', 'my head', 'my neighbour', 'my phone', 'my pick', 'my room', 'my train', 'myanmar', 'myanmar displace', 'mystery', 'na', 'nagasaki', 'nagasaki atomic', 'nah', 'name', 'name the', 'nap', 'nasa', 'nashville', 'nashville theater', 'nasty', 'nation', 'national', 'national forest', 'national park', 'natural', 'natural calamity', 'natural disaster', 'nature', 'navy', 'navy sideline', 'nazi', 'nb', 'nc', 'nd', 'near', 'near house', 'nearby', 'nearby home', 'nearby what', 'nearly', 'need', 'need be', 'need get', 'need stop', 'negative', 'neighbor', 'neighborhood', 'neighbour', 'neighbour ass', 'neither', 'nema', 'never', 'never forget', 'never know', 'new', 'new content', 'new explosionproof', 'new home', 'new lady', 'new mad', 'new post', 'new sub', 'new world', 'new york', 'new yorker', 'news', 'news bbc', 'news hostage', 'news trs', 'news unconfirmed', 'newyork', 'next', 'next door', 'next week', 'next year', 'nice', 'niece', 'nigerian', 'nigerian refugee', 'nigga', 'niggas', 'night', 'night be', 'night lucky', 'nike', 'nine', 'no', 'no curfew', 'no one', 'no return', 'nobody', 'non', 'none', 'normal', 'north', 'northern', 'northern california', 'northern marians', 'nose', 'not', 'not believe', 'not die', 'not electrocute', 'not even', 'not find', 'not forget', 'not get', 'not go', 'not hear', 'not help', 'not it', 'not know', 'not let', 'not like', 'not make', 'not miss', 'not say', 'not see', 'not sink', 'not survive', 'not take', 'not tell', 'not the', 'not think', 'not wait', 'not want', 'not watch', 'not weapon', 'not worry', 'note', 'nothing', 'notice', 'notice stab', 'notification', 'now', 'now be', 'now quarantine', 'nowplaye', 'nowplaying', 'nri', 'nri news', 'nu', 'nuclear', 'nuclear bomb', 'nuclear disaster', 'nuclear emergency', 'nuclear power', 'nuclear reactor', 'nuclear weapon', 'nude', 'number', 'nurse', 'nursing', 'nursing job', 'nw', 'nws', 'ny', 'nyc', 'nytime', 'o784', 'o784 involve', 'oak', 'obama', 'obama declare', 'obama sign', 'object', 'obliterate', 'obliterate planned', 'obliterate the', 'obliteration', 'obliteration ancient', 'oc', 'oc share', 'occur', 'occur star', 'ocean', 'odeon', 'odeon cinema', 'of', 'of bed', 'of volcano', 'off', 'offensive', 'offensive content', 'offer', 'office', 'officer', 'officer wound', 'official', 'official alabama', 'official say', 'official vid', 'official video', 'officially', 'officially explode', 'offroad', 'offroad fog', 'offroad lamp', 'often', 'oh', 'oh god', 'oh wait', 'oil', 'oil gas', 'oil spill', 'ok', 'ok ok', 'okay', 'oklahoma', 'oklahoma county', 'okwx', 'old', 'old pkk', 'olympic', 'omg', 'on', 'on fire', 'once', 'one', 'one day', 'one direction', 'one my', 'one the', 'one they', 'one thing', 'one time', 'online', 'onlinecommunitie', 'onlinecommunitie reddit', 'only', 'only one', 'ontario', 'onto', 'oop', 'op', 'open', 'open the', 'opening', 'operation', 'opinion', 'oppression', 'oppression great', 'option', 'opus', 'or', 'oral', 'orange', 'order', 'order evacuation', 'order lift', 'order obliteration', 'origin', 'original', 'ornament', 'os', 'os come', 'other', 'our', 'out', 'out story', 'outbreak', 'outbreak legionnaire', 'outlook', 'outlook hwo', 'outrage', 'outrage amid', 'outside', 'over', 'overload', 'overlook', 'overnight', 'own', 'owner', 'owner chicagoarea', 'owner whip', 'pace', 'pack', 'page', 'pain', 'paint', 'pair', 'pak', 'pakistan', 'pakistani', 'pakistani air', 'palestine', 'palestinian', 'palestinians', 'palin', 'palin obliterate', 'palm', 'pam', 'pamela', 'pamela geller', 'pandemonium', 'pandemonium aba', 'pandemonium the', 'panic', 'panic attack', 'panic cable', 'panic the', 'pantherattack', 'paper', 'parent', 'parent colorado', 'parenthood', 'parenthood target', 'park', 'park service', 'parker', 'parker ridge', 'parleys', 'parleys canyon', 'parole', 'parole california', 'parole school', 'part', 'part the', 'partner', 'party', 'party massacre', 'pass', 'passenger', 'password', 'past', 'past anniversary', 'patch', 'patch os', 'path', 'pathogen', 'patience', 'patience jonathan', 'patient', 'patrick', 'paul', 'pay', 'pay pile', 'pdp', 'peace', 'peace ie', 'peace upon', 'peaceful', 'pedestrian', 'peep', 'penalty', 'people', 'people be', 'people die', 'people finally', 'people horror', 'people kill', 'pepper', 'percent', 'perfect', 'perhaps', 'person', 'personal', 'petition', 'petition heartless', 'philippine', 'philly', 'phoenix', 'phone', 'phone and', 'photo', 'photo bomb', 'photography', 'photography art', 'physical', 'physician', 'pic', 'pic 16yr', 'pick', 'pick fan', 'picking', 'picking body', 'picture', 'piece', 'piece wreckage', 'pile', 'pill', 'pilot', 'pipeline', 'pit', 'pitch', 'pitcher', 'pizza', 'pkk', 'pkk suicide', 'place', 'place the', 'plague', 'plague farrakhan', 'plain', 'plain american', 'plan', 'plan former', 'plan hijack', 'plane', 'plane crash', 'plane debris', 'planet', 'planned', 'planned parenthood', 'plant', 'plate', 'play', 'player', 'playlist', 'playlist panic', 'playoff', 'please', 'please favorite', 'please rt', 'plot', 'pls', 'plug', 'plug christmas', 'plummet', 'plunging', 'plunging water', 'plus', 'pm', 'pm edt', 'pm investigator', 'pocket', 'point', 'point no', 'police', 'police kill', 'police officer', 'police post', 'police say', 'policy', 'policy go', 'policy promise', 'politic', 'politic grief', 'political', 'poll', 'poll tension', 'pond', 'pond lownde', 'pool', 'poor', 'pop', 'pop quiz', 'population', 'porn', 'port', 'portland', 'positive', 'possible', 'possible ebola', 'possibly', 'post', 'post spos', 'potential', 'potential bioterror', 'potus', 'potus strategicpatience', 'pound', 'pour', 'pov', 'poverty', 'power', 'power red', 'powerful', 'powerline', 'ppl', 'practice', 'pradesh', 'pradesh train', 'pray', 'pray attack', 'prayer', 'pre', 'prebreak', 'prebreak well', 'predict', 'prefer', 'prepare', 'prepare for', 'preparedness', 'preparedness library', 'present', 'president', 'press', 'pressure', 'pretty', 'prevent', 'previously', 'price', 'primary', 'prime', 'prince', 'print', 'prior', 'priority', 'prison', 'prison like', 'private', 'pro', 'probably', 'problem', 'prod', 'produce', 'profile', 'program', 'progress', 'project', 'promise', 'promise quarantine', 'prompt', 'property', 'property damage', 'property sit', 'prophet', 'prophet peace', 'prophetmuhammad', 'prophetmuhammad islam', 'prosecute', 'prosecute fukushima', 'protect', 'protector', 'protector film', 'protest', 'provide', 'providence', 'providence health', 'provoke', 'provoke outrage', 'psychiatric', 'ptsd', 'public', 'pull', 'pump', 'pun', 'punish', 'puppy', 'purple', 'purse', 'purse cross', 'pussy', 'put', 'putin', 'quality', 'quarantine', 'quarantine extremely', 'quarantine offensive', 'quarantine possible', 'quarantined', 'quarantined prebreak', 'quarter', 'queen', 'quest', 'question', 'quick', 'quickly', 'quiz', 'quiz do', 'quote', 'quran', 'quran lie', 'race', 'radar', 'radiation', 'radio', 'rage', 'rage forest', 'raid', 'rail', 'rail crash', 'railway', 'rain', 'rainstorm', 'rally', 'ramag', 'ramag fashion', 'range', 'rank', 'rape', 'rapidly', 'rapper', 'rare', 'rate', 'rather', 'ray', 'raynbowaffair', 'raynbowaffair editor', 'raze', 'raze northern', 'rd', 're', 're bleed', 're go', 're totally', 'rea', 'reach', 'react', 'reactor', 'read', 'read by', 'read ebay', 'reading', 'ready', 'real', 'realdonaldtrump', 'realise', 'realise be', 'reality', 'realize', 'really', 'really like', 'reap', 'rear', 'rear technology', 'reason', 'reason we', 'recall', 'recap', 'receive', 'recent', 'recently', 'recommend', 'record', 'recount', 'recount horror', 'recover', 'recovery', 'red', 'reddit', 'reddit cofounder', 'reddit new', 'reddit now', 'reddit update', 'reduce', 'reduce civilian', 'refer', 'reflect', 'refugee', 'refugee idp', 'refugee repatriate', 'refugio', 'refugio oil', 'refuse', 'region', 'register', 'regret', 'regular', 'reject', 'relate', 'relate article', 'relationship', 'relative', 'relative hope', 'relax', 'release', 'release chile', 'release issue', 'relief', 'remain', 'remember', 'remember time', 'remind', 'reminder', 'removal', 'remove', 'remove and', 'reopen', 'rep', 'repair', 'repatriate', 'repatriate cameroon', 'repeat', 'replace', 'report', 'report 11yearold', 'report say', 'reportedly', 'reportedly kill', 'republican', 'republicans', 'require', 'rescue', 'rescue hostage', 'rescue med', 'rescue oc', 'rescue the', 'rescuer', 'rescuer search', 'research', 'research specimen', 'reshape', 'reshape rock', 'resident', 'residential', 'residential area', 'respect', 'respond', 'responder', 'response', 'responsibility', 'responsible', 'rest', 'restore', 'restrict', 'result', 'result 2014', 'return', 'return prison', 'reunion', 'reunion from', 'reunion island', 'reuter', 'reuters', 'reuters three', 'reveal', 'review', 'revolution', 'reward', 'rexyy', 'rexyy towel', 'richmond', 'richmond police', 'ride', 'rider', 'ridge', 'ridge wildfire', 'right', 'ring', 'riot', 'riot grill', 'rioting', 'rip', 'rise', 'rise the', 'rise wildfire', 'risk', 'river', 'river wild', 'rly', 'rly tragedy', 'rn', 'road', 'rob', 'robert', 'robinson', 'robot', 'robot could', 'rock', 'rock the', 'rocket', 'rocky', 'rocky fire', 'rockyfire', 'roger', 'rohingya', 'rohingya sittwe', 'role', 'roll', 'roller', 'romance', 'rome', 'rome reuters', 'roof', 'room', 'roosevelt', 'roosevelt wash', 'root', 'ross', 'ross dead', 'round', 'route', 'royal', 'rt', 'rt abbswinston', 'rubber', 'rubble', 'rubble china', 'ruin', 'ruin everything', 'rule', 'rule catastrophic', 'rule change', 'run', 'run burn', 'run riot', 'runner', 'running', 'runway', 'russia', 'russian', 'russian food', 'ryan', 'rì', 'rì union', 'sa', 'sad', 'saddlebrooke', 'sadly', 'safe', 'safely', 'safety', 'saipan', 'saipan obama', 'sale', 'salem', 'salt', 'salt river', 'same', 'sample', 'san', 'sanction', 'sandiego', 'sandstorm', 'sandstorm under', 'santa', 'sarah', 'sarah palin', 'sassy', 'sassy city', 'satchel', 'satellite', 'saturday', 'saudi', 'saudi arabia', 'saudi mosque', 'saudi security', 'save', 'save from', 'save many', 'saving', 'say', 'say be', 'say fatal', 'say have', 'say save', 'say the', 'say virgin', 'scare', 'scared', 'scary', 'scene', 'schedule', 'scheme', 'school', 'school bus', 'science', 'science that', 'scientist', 'score', 'scotland', 'scott', 'scream', 'scream the', 'screen', 'screen protector', 'screenshot', 'screenshot show', 'screw', 'se', 'sea', 'search', 'search hundred', 'search survivor', 'season', 'seat', 'seattle', 'second', 'secret', 'section', 'secure', 'security', 'security site', 'see', 'see coach', 'see lightning', 'seek', 'seek comment', 'seem', 'seem like', 'seismic', 'seismic intensity', 'seismic shift', 'self', 'selfie', 'selfie will', 'selfimage', 'selfimage take', 'senate', 'senator', 'send', 'send datum', 'senior', 'sense', 'sensor', 'sensorsenso', 'sensorsenso standard', 'serial', 'series', 'serious', 'seriously', 'serve', 'server', 'service', 'service center', 'service sound', 'service tonto', 'set', 'seven', 'several', 'severe', 'severe rainstorm', 'severe thunderstorm', 'severe weather', 'sex', 'sexual', 'sf', 'sh', 'shadow', 'shake', 'shall', 'shame', 'shanghai', 'shape', 'shape its', 'share', 'share link', 'shark', 'sharp', 'she', 'she go', 'sheet', 'shelter', 'shepherd', 'shepherd rescue', 'shift', 'shift focus', 'ship', 'ship potential', 'shirt', 'shit', 'shit like', 'shock', 'shoot', 'shooting', 'shooting victim', 'shop', 'short', 'shot', 'shot richmond', 'should', 'should not', 'shoulder', 'shoulder bag', 'shoulder tote', 'shout', 'show', 'show lovely', 'shower', 'shut', 'sicily', 'sick', 'sick injure', 'side', 'sideline', 'sideline new', 'sigalert', 'sign', 'sign could', 'sign disaster', 'sign petition', 'silence', 'silent', 'silver', 'silver spring', 'simple', 'simulate', 'simulate chemical', 'since', 'since 2013', 'since the', 'sing', 'singe', 'single', 'sinjar', 'sinjar massacre', 'sink', 'sink low', 'sink ship', 'sink the', 'sinkhole', 'sinkhole open', 'sinkhole selfie', 'sinkhole swallow', 'sinking', 'sinking feel', 'sir', 'siren', 'sismo', 'sismo 19', 'sismo detectado', 'sister', 'sit', 'sit vacant', 'site', 'site mosque', 'sittwe', 'sittwe point', 'situation', 'six', 'sixth', 'size', 'skill', 'skin', 'sky', 'slam', 'slanglucci', 'slanglucci oppression', 'slate', 'sleep', 'sleep siren', 'slide', 'slightly', 'slip', 'slow', 'slowly', 'sm', 'small', 'small earthquake', 'smash', 'smaug', 'smh', 'smile', 'smithsonian', 'smoke', 'smoke the', 'smoky', 'smoky mountain', 'smooth', 'snap', 'snapchat', 'snow', 'snowstorm', 'snowstorm aoms', 'so', 'so good', 'so much', 'soak', 'soccer', 'social', 'social casualty', 'society', 'solar', 'soldier', 'solid', 'solution', 'solve', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometimes', 'son', 'song', 'soon', 'soon album', 'sorry', 'soudelor', 'soudelor take', 'soul', 'sound', 'sound alarm', 'sound like', 'sound wave', 'soundcloud', 'source', 'south', 'southbound', 'southdown', 'southern', 'soviet', 'sp', 'space', 'space battle', 'spaceship', 'spaceship crash', 'spain', 'spanish', 'spark', 'speak', 'speaker', 'spear', 'special', 'specially', 'specially modify', 'specif', 'specimen', 'spend', 'spend wedding', 'spider', 'spill', 'spill estimate', 'spill may', 'spin', 'spirit', 'split', 'sport', 'spos', 'spos injure', 'spot', 'spot flood', 'spread', 'spring', 'spring 2013', 'spring oil', 'sprinter', 'sprinter automatic', 'squad', 'squeeze', 'st', 'stab', 'stab arson', 'stadium', 'stadium rescue', 'staff', 'stage', 'stand', 'stand with', 'standard', 'standard fit', 'standus', 'standus you', 'star', 'star o784', 'star war', 'start', 'start forest', 'starter', 'startup', 'starve', 'stat', 'state', 'state action', 'state group', 'statement', 'statement issue', 'states', 'station', 'status', 'stay', 'stay tune', 'steal', 'steam', 'steel', 'step', 'stephen', 'steve', 'steve huffman', 'stewart', 'stick', 'still', 'still burn', 'still do', 'still feel', 'still get', 'still have', 'still struggle', 'still the', 'stir', 'stir politic', 'stock', 'stock market', 'stone', 'stop', 'stop annihilation', 'stop deadly', 'stop ship', 'store', 'storm', 'storm combat', 'storm pass', 'story', 'story america', 'story via', 'straight', 'strand', 'strand smoky', 'strange', 'strategicpatience', 'strategicpatience strategy', 'strategy', 'strategy genocide', 'streak', 'streak tripledigit', 'stream', 'street', 'stress', 'stretcher', 'strike', 'strike live', 'strip', 'strong', 'strong thunderstorm', 'structural', 'structural failure', 'structure', 'struggle', 'struggle war', 'stuart', 'stuart broad', 'student', 'study', 'stuff', 'stupid', 'style', 'sub', 'subject', 'subreddit', 'subreddit ban', 'such', 'suck', 'suddenly', 'sue', 'sue legionnaire', 'suffer', 'suicide', 'suicide attack', 'suicide bomb', 'suicide bomber', 'suicide bombing', 'summer', 'summer spark', 'summer war', 'summerfate', 'sun', 'sunday', 'sunset', 'super', 'supernatural', 'support', 'suppose', 'sure', 'surface', 'surge', 'surprise', 'surround', 'survival', 'survive', 'survive hiroshima', 'survive without', 'survivor', 'survivor boat', 'survivor the', 'suspect', 'suspect dead', 'suspect kill', 'suspect link', 'suspect militant', 'sw', 'swallow', 'swallow by', 'swallow entire', 'swallows', 'swear', 'sweep', 'sweet', 'swim', 'swimming', 'syria', 'syrian', 'syrian refugee', 'system', 'table', 'tablet', 'tablet hieroglyphic', 'tag', 'taiwan', 'take', 'take away', 'take break', 'take care', 'take dead', 'take life', 'take look', 'take place', 'take quiz', 'taliban', 'talk', 'talk it', 'tank', 'tape', 'target', 'target minority', 'taste', 'taste like', 'tax', 'tbt', 'tcot', 'tdp', 'tdp bjp', 'team', 'tear', 'tech', 'technology', 'technology cool', 'ted', 'ted cruz', 'teen', 'tell', 'tell can', 'temper', 'temper glass', 'temple', 'temple mount', 'ten', 'tension', 'tension bayelsa', 'tent', 'tent collapse', 'term', 'terrible', 'terror', 'terror attack', 'terrorism', 'terrorism africa', 'terrorism quran', 'terrorist', 'terrorist the', 'test', 'texas', 'texas seek', 'text', 'th', 'than', 'than 40', 'thank', 'thank for', 'thank god', 'thank the', 'that', 'that be', 'that one', 'that piece', 'that you', 'the', 'the action', 'the air', 'the apocalypse', 'the area', 'the atomic', 'the avalanche', 'the bad', 'the ball', 'the blaze', 'the blight', 'the bomb', 'the brooklyn', 'the building', 'the burn', 'the collapse', 'the community', 'the copilot', 'the dark', 'the day', 'the death', 'the deluge', 'the devastation', 'the disco', 'the earth', 'the emergency', 'the end', 'the enemy', 'the epicentre', 'the family', 'the fatal', 'the fire', 'the first', 'the flame', 'the follow', 'the game', 'the good', 'the ground', 'the hiroshima', 'the hospital', 'the internet', 'the just', 'the last', 'the lord', 'the main', 'the mass', 'the mediterran', 'the mediterranean', 'the middle', 'the military', 'the moon', 'the movie', 'the mudslide', 'the name', 'the new', 'the night', 'the old', 'the one', 'the past', 'the pay', 'the people', 'the police', 'the property', 'the rescue', 'the road', 'the rubble', 'the salt', 'the side', 'the sky', 'the state', 'the storm', 'the suicide', 'the temple', 'the time', 'the toilet', 'the top', 'the train', 'the us', 'the way', 'the west', 'the whole', 'the wild', 'the world', 'the wrong', 'theater', 'theater attack', 'theater shooting', 'theatre', 'their', 'theme', 'then', 'theory', 'therapy', 'there', 'there fire', 'there gem', 'there no', 'there nothing', 'these', 'they', 'they do', 'they re', 'they ve', 'thing', 'think', 'think be', 'think get', 'think he', 'think you', 'thinking', 'third', 'this', 'this one', 'tho', 'thomas', 'those', 'those be', 'though', 'thought', 'thousand', 'threat', 'threaten', 'threaten kill', 'three', 'three people', 'three rome', 'throw', 'thru', 'thunder', 'thunder lightning', 'thunderstorm', 'thunderstorm warn', 'thunderstorm warning', 'thursday', 'thus', 'thx', 'ticket', 'tie', 'till', 'time', 'time do', 'time have', 'time the', 'time20150805', 'time20150806', 'time20150806 010401', 'times', 'tinyjecht', 'tinyjecht another', 'tip', 'tired', 'title', 'to', 'to cook', 'to drown', 'to explode', 'to get', 'to go', 'to ruin', 'to stop', 'to the', 'to think', 'to work', 'today', 'today the', 'toddler', 'toddler report', 'toe', 'together', 'toilet', 'toll', 'tom', 'tomorrow', 'tomorrow night', 'ton', 'tonight', 'tonight attack', 'tonto', 'tonto national', 'too', 'too traumatised', 'tool', 'tooth', 'top', 'top link', 'top the', 'torch', 'tornado', 'tornado flood', 'total', 'totally', 'totally obliterate', 'tote', 'tote handbag', 'touch', 'tour', 'toward', 'towards', 'towel', 'town', 'township', 'township fire', 'tr', 'track', 'traditional', 'traffic', 'trafford', 'trafford centre', 'tragedy', 'tragedy mp', 'trail', 'trailer', 'train', 'train derail', 'train derailment', 'train plunging', 'train wreck', 'training', 'tram', 'transit', 'transport', 'transport bioterror', 'transport research', 'trap', 'trap miner', 'trapmusic', 'trapmusic dnb', 'trash', 'trauma', 'traumatise', 'traumatised', 'travel', 'travel guide', 'travel update', 'treat', 'treatment', 'tree', 'tree report', 'trench', 'trench release', 'trend', 'trent', 'trent bridge', 'trfc', 'trfc collisionno', 'trial', 'tribal', 'tribal war', 'trigger', 'trip', 'triple', 'tripledigit', 'tripledigit heat', 'trolley', 'trolley service', 'troop', 'troop kill', 'tropical', 'tropical cyclone', 'trouble', 'trs', 'trs tdp', 'trubgme', 'truck', 'truck boat', 'truck fire', 'truck use', 'true', 'truly', 'trump', 'trunk', 'trust', 'truth', 'truth god', 'truth news', 'try', 'try do', 'try get', 'tryna', 'ts', 'ts nri', 'tsunami', 'tube', 'tube strike', 'tubestrike', 'tumble', 'tune', 'turkey', 'turkey army', 'turkish', 'turkish couple', 'turkish troop', 'turn', 'turn into', 'tv', 'tweet', 'twelve', 'twelve fear', 'twice', 'twin', 'twister', 'twitter', 'two', 'two building', 'two car', 'two giant', 'two people', 'two train', 'two year', 'ty', 'type', 'typhoon', 'typhoon soudelor', 'typhoondevastate', 'typhoondevastate saipan', 'ud', 'udhampur', 'udhampur terror', 'ugh', 'ugly', 'uk', 'ultimalucha', 'ultimate', 'ultimate preparedness', 'uncle', 'unconfirmed', 'unconfirmed just', 'under', 'under minute', 'understand', 'uniform', 'union', 'union island', 'unit', 'unit 731', 'unit simulate', 'united', 'united states', 'universe', 'unknown', 'unless', 'unlock', 'unlock brake', 'unsafe', 'unveil', 'unveil specif', 'up', 'update', 'update content', 'update london', 'upgrade', 'upheaval', 'upheaval the', 'upon', 'upon say', 'upper', 'upset', 'ur', 'ur destiny', 'ur life', 'uribe', 'us', 'us national', 'us navy', 'usa', 'usagov', 'usagov auth', 'usatoday', 'use', 'use nuclear', 'user', 'user download', 'usgs', 'usgs eq', 'usual', 'usually', 'utc', 'utc earthquake', 'utc20150805', 'utc20150805 150401', 'utter', 'va', 'vacant', 'vacant since', 'val', 'valley', 'value', 'van', 'variety', 've', 've get', 'vehicle', 'vehicle choice', 'vehicle collide', 'verdict', 'version', 'very', 'vet', 'veteran', 'vi', 'via', 'via change', 'via pamela', 'via youtube', 'victim', 'victim fear', 'victim stir', 'victory', 'vid', 'video', 'video capture', 'video minecraft', 'video picking', 'video show', 'video youtube', 'vietnam', 'view', 'view download', 'village', 'village youth', 'vine', 'vintage', 'vinyl', 'violent', 'violent storm', 'viralspell', 'virgin', 'virgin galactic', 'visit', 'vladimir', 'vladimir putin', 'voice', 'volcano', 'volcano hawaii', 'vote', 'voter', 'vs', 'vuitton', 'vulnerable', 'wa', 'waimate', 'waimate fire', 'wait', 'wait the', 'wake', 'wake anthrax', 'wake to', 'wake up', 'walk', 'walker', 'wall', 'walmart', 'wan', 'wan na', 'wannabe', 'want', 'want be', 'want make', 'want see', 'want to', 'want work', 'war', 'war past', 'war turn', 'war zone', 'warfighte', 'warfighte robot', 'warm', 'warming', 'warn', 'warn public', 'warning', 'warning be', 'warning issue', 'warning oklahoma', 'warning wind', 'warship', 'wash', 'washington', 'washington post', 'waste', 'watch', 'watch airport', 'watch sarah', 'watch show', 'water', 'water call', 'water main', 'water rescuer', 'waterway', 'wave', 'wave black', 'wave israeli', 'way', 'we', 'we get', 'we help', 'we love', 'we still', 'we ve', 'we will', 'weak', 'wealth', 'weapon', 'wear', 'weather', 'weather bulletin', 'weather outlook', 'weather statement', 'website', 'wedding', 'wedding day', 'wednesday', 'weed', 'week', 'weekend', 'weigh', 'weird', 'welcome', 'well', 'well do', 'well know', 'west', 'west coast', 'western', 'wet', 'whale', 'what', 'what appear', 'what do', 'what the', 'wheavenly', 'wheavenly blessing', 'when', 'where', 'whether', 'which', 'while', 'whip', 'whip horse', 'whirlwind', 'white', 'white mass', 'who', 'whole', 'whole time', 'why', 'wicked', 'widespread', 'wife', 'wild', 'wild fire', 'wild horse', 'wildfire', 'wildfire abc', 'wildfire cost', 'wildfire destroy', 'will', 'will get', 'will never', 'will not', 'will win', 'williams', 'willing', 'win', 'win landslide', 'wind', 'wind 60', 'wind gust', 'wind my', 'window', 'windstorm', 'windstorm insurer', 'wing', 'winston', 'winter', 'wire', 'wire reddit', 'wish', 'with', 'with colour', 'with killer', 'wither', 'wither 20', 'within', 'without', 'without face', 'witness', 'wmata', 'woman', 'woman crush', 'woman deliver', 'woman the', 'woman ûò', 'women', 'wonder', 'wonderful', 'wood', 'word', 'word wreck', 'work', 'work light', 'work the', 'worker', 'world', 'world collide', 'world news', 'world riot', 'world war', 'worldnew', 'worry', 'worstsummerjob', 'worth', 'would', 'would be', 'would come', 'would explode', 'would get', 'would love', 'would not', 'would say', 'would ve', 'would you', 'wound', 'wound suspect', 'wow', 'wrap', 'wreck', 'wreck the', 'wreckage', 'wreckage conclusively', 'wreckage flight', 'write', 'writer', 'wrong', 'wrought', 'wtf', 'ww1', 'wwii', 'wx', 'wy', 'xbox', 'xd', 'ya', 'yay', 'yea', 'yeah', 'year', 'year ago', 'year atomic', 'year be', 'year cause', 'year ferguson', 'year old', 'year since', 'yell', 'yellow', 'yes', 'yesterday', 'yet', 'yo', 'york', 'york times', 'yorker', 'you', 'you all', 'you be', 'you can', 'you do', 'you get', 'you go', 'you have', 'you know', 'you like', 'you ll', 'you re', 'you say', 'you see', 'you the', 'you ve', 'you with', 'you ûªve', 'young', 'youngheroesid', 'youngheroesid lava', 'your', 'your health', 'your phone', 'yours', 'youth', 'youth save', 'youtube', 'youtube playlist', 'youtube video', 'yr', 'yyc', 'z10', 'z10 full', 'zionist', 'zionist terrorist', 'zone', 'zouma', 'åê', 'ûª', 'ûª israel', 'ûªs', 'ûªs first', 'ûªs stock', 'ûªt', 'ûªt let', 'ûªve', 'ûªve at', 'ûïa', 'ûïhatchet', 'ûïhatchet control', 'ûïthe', 'ûïwhen', 'ûïwhen see', 'ûò', 'ûò bb4sp', 'ûó']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2284, 4815)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngram for log regression\n",
    "for i in range(1,9):\n",
    "    CountVec_ngram = CountVectorizer(ngram_range = (1, 2), min_df = i)\n",
    "    #transform\n",
    "    Countgram_train = CountVec_ngram.fit_transform(x_train).toarray()\n",
    "    Countgram_valid = CountVec_ngram.transform(x_valid).toarray()\n",
    "    logreg_gram = LogisticRegression()\n",
    "    logreg_gram.fit(Countgram_train,y_train)\n",
    "    predict_y_gram = logreg_gram.predict(Countgram_valid)\n",
    "    print('With M = %s, F1 score = %.4f' % (i, f1_score(y_valid, predict_y_gram)))\n",
    "    \n",
    " \n",
    "#use M = 3\n",
    "count_gram_real = CountVectorizer(ngram_range = (1, 2),binary=True, min_df=3)\n",
    "Countgram_train_real = count_gram_real.fit_transform(x_train).toarray()\n",
    "gramnames = count_gram_real.get_feature_names()\n",
    "print(gramnames)\n",
    "Countgram_valid_real = count_gram_real.transform(x_valid).toarray()\n",
    "Countgram_valid_real.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with logreg: 0.7492\n",
      "drought\n",
      "terrorism\n",
      "storm\n",
      "evacuate\n",
      "typhoon\n",
      "earthquake\n",
      "wildfire\n",
      "bombing\n",
      "massacre\n",
      "hiroshima\n"
     ]
    }
   ],
   "source": [
    "#find out f1_score and the 10 most common names to determine if the tweet is about disaster\n",
    "lr_l2_gram = LogisticRegression(penalty = 'l2')\n",
    "lr_l2_gram.fit (Countgram_train_real, y_train)\n",
    "prediction_y_gram = lr_l2_gram.predict(Countgram_valid_real)\n",
    "print('F1 score with logreg: %.4f' % f1_score(y_valid, prediction_y_gram))\n",
    "weights = lr_l2_gram.coef_[0]\n",
    "sorted_weight_index = np.argsort(np.abs(lr_l2_gram.coef_[0])) #return the index of the sorted weights \n",
    "for i in sorted_weight_index[-10:]:\n",
    "    print(gramnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 2gram names are:  1877\n",
      "The number of 1gram names are:  2938\n"
     ]
    }
   ],
   "source": [
    "## Count # of 1-gram and 2gram vocab\n",
    "\n",
    "twogram = []\n",
    "for words in gramnames:\n",
    "    if \" \" in words: \n",
    "        twogram.append(words)\n",
    "twogramNum = len(twogram)   \n",
    "onegramNum = len(gramnames)-twogramNum\n",
    "        \n",
    "print('The number of 2gram names are: ', twogramNum)\n",
    "print('The number of 1gram names are: ', onegramNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes + N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56370801 0.43629199]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_gram = Countgram_train_real.shape[0] # size of the dataset\n",
    "d_gram = Countgram_train_real.shape[1] # number of features in our dataset\n",
    "K_gram = 2 # number of clases\n",
    "\n",
    "# these are the shapes of the parameters\n",
    "psis = np.zeros([K_gram,d_gram])\n",
    "phis = np.zeros([K_gram])\n",
    "\n",
    "# we now compute the parameters\n",
    "for k in range(K_gram):\n",
    "    gramTrain_k = Countgram_train_real[y_train == k]\n",
    "    psis[k] = np.mean(gramTrain_k, axis=0)\n",
    "    phis[k] = gramTrain_k.shape[0] / float(n)\n",
    "\n",
    "# print out the class proportions\n",
    "print(phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 1 1 0]\n",
      "Mean of predicted results on training data using Naive Bayes and N gram: 0.8698\n",
      "Mean of predicted results on valid data: 0.8021\n",
      "F1 score on the training set: 0.8352\n",
      "F1 score on the dev set: 0.7303\n"
     ]
    }
   ],
   "source": [
    "def nb_predictions_gram(x, psis, phis):\n",
    "    #This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    #We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "\n",
    "    # adjust shapes\n",
    "    n_gram, d_gram = x.shape\n",
    "    x = np.reshape(x, (1, n_gram, d_gram))\n",
    "    psis = np.reshape(psis, (K_gram, 1, d_gram))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14)\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape([K_gram,1])\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K_gram,n_gram])\n",
    "\n",
    "idx_gram, logpyx_gram = nb_predictions(Countgram_train_real, psis, phis)\n",
    "idx_valid_gram, logpyx_valid_gram = nb_predictions(Countgram_valid_real, psis, phis)\n",
    "print(idx[:10])\n",
    "\n",
    "print('Mean of predicted results on training data using Naive Bayes and N gram: %.4f' % (idx_gram==y_train).mean())\n",
    "print('Mean of predicted results on valid data: %.4f' % (idx_valid_gram==y_valid).mean())\n",
    "print(\"F1 score on the training set: %.4f\" % f1_score(y_train, idx_gram))\n",
    "print(\"F1 score on the dev set: %.4f\" % f1_score(y_valid, idx_valid_gram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Based on the result comparison, the 10 most common words that indicating the disaster tweet change slightly between the N-gram and bag of words methods, but overall the predicted results and F1 score doesn't differ a lot between both models. This may implies that there are many ways for us to do this problem, different models may yeild an overall similar result and lead to the same direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine performance with the test set Re-build your feature vectors and re-train your preferred classifier (either bag of word or n-gram using either logistic regression or Bernoulli naive bayes) using the entire Kaggle training data (i.e. using all of the data in both the training and development sets). Then, test it on the Kaggle test data. Submit your results to Kaggle, and report the resulting F 1-score on the test data, as reported by Kaggle. Was this lower or higher than you expected? Discuss why it might be lower or higher than your expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing test data -- Lowercase----------------------------------------------------------------------------------------------------------\n",
    "testData['text'] = testData['text'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "## strip urls-------------------------------------------------------------------------------------------------------------------\n",
    "for l in range(0,len(testData['text'])): \n",
    "    testData['text'][l] = re.sub(r'http\\S+', '', testData['text'][l])\n",
    "    testData['text'][l] = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', testData['text'][l])\n",
    "\n",
    "    \n",
    "## get ride of punctuation----------------------------------------------------------------------------------------------------------\n",
    "testData['text'] = testData['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "\n",
    "## strip stop words ----------------------------------------------------------------------------------------------------------\n",
    "text_token_test = []\n",
    "temp_test = testData['text']\n",
    "for i in range(0,len(testData['text'])): \n",
    "    text_token_test.append(word_tokenize(temp_test[i]))\n",
    "for row in range(0,len(text_token_test)):\n",
    "    for word in text_token_test[row]:\n",
    "        if word in stopwords.words('english'):\n",
    "            text_token_test[row].remove(word)\n",
    "        \n",
    "            \n",
    "    text_token_test[row] =  (\" \").join(text_token_test[row])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lamatize Test data----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "clean_token_test = []\n",
    "lemmatized_sentence_test = []\n",
    "\n",
    "for l in range(0,len(text_token_test)):\n",
    "    text_token_test[l] = nlp(text_token_test[l])\n",
    "    for tokes in text_token_test[l]:\n",
    "        clean_token_test.append(tokes)\n",
    "        \n",
    "    lemmatized_sentence_test.append(\" \".join([tokes.lemma_ for tokes in text_token_test[l]]))  \n",
    "    \n",
    "\n",
    "clean_sent_test = pd.DataFrame({'clean_Text':lemmatized_sentence_test})\n",
    "new_testData = pd.concat([testData, clean_sent_test],join = 'outer', axis = 1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>hear earthquake different city stay safe everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "      <td>be forest fire spot pond geese flee across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 just happened a terrible car crash   \n",
       "1   2     NaN      NaN  heard about earthquake is different cities sta...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond geese are ...   \n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n",
       "4  11     NaN      NaN      typhoon soudelor kills 28 in china and taiwan   \n",
       "\n",
       "                                          clean_Text  \n",
       "0                          happen terrible car crash  \n",
       "1  hear earthquake different city stay safe everyone  \n",
       "2  be forest fire spot pond geese flee across str...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4              typhoon soudelor kill 28 china taiwan  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5562)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use M = 2\n",
    "count_vect_final = CountVectorizer(binary=True, min_df=2)\n",
    "CountVec_train_final = count_vect_final.fit_transform(new_trainData['clean_Text']).toarray()\n",
    "vnames = count_vect_real.get_feature_names()\n",
    "#print(vnames)\n",
    "CountVec_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------next page -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 5562)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dev set to bag of word\n",
    "count_test_final = count_vect_final.transform(new_testData['clean_Text']).toarray()\n",
    "# sanity check\n",
    "count_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression(penalty = 'l2')\n",
    "lr_final.fit(CountVec_train_final, new_trainData['target'])\n",
    "predict_test_final = lr_final.predict(count_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Final result.csv', mode='w+') as rfile:\n",
    "    rfile.write('id,target\\n')\n",
    "    for (id, tg) in zip(new_testData['id'].values, predict_test_final):\n",
    "        rfile.write('%s,%s\\n'%(id, tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Based on the F1 score return from Kaggle, we get 0.78608 F1 score for this problem. This score is within our expectation as we chosed Bag of words and Logistics regressions as our methods, which is pretty aligned with the F1 score we received during the training and validation process. I expect our F1 score to be higher if we use naive bayes method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
